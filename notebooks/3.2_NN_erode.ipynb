{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/Users/chikakoolsen/opt/python/thesis/code/tdcs_thesis/\"\n",
    "# dir_path = \"/Users/mriworkshop/Documents/TDCS/code/tdcs_thesis/\"\n",
    "save_path = dir_path+\"data/raw/\"\n",
    "img_path =  dir_path+\"data/processed/\"\n",
    "model_path = dir_path+\"models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fmap mean all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mean = save_path+\"fmap_mean_erode.txt\"\n",
    "columns_mean =['exp', 'mini_exp', 'i', 'j', 'k', 'mean0', 'mean1', 'mean2', 'mean3', 'mean4', 'theory']\n",
    "data = np.loadtxt(file_mean);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>mini_exp</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>theory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046267</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046268</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046269</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046270</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046271</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5046272 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         exp  mini_exp   i   j   k  mean0  mean1  mean2  mean3  mean4  theory\n",
       "0         36         1   0   0   0    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "1         36         1   0   0   1    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "2         36         1   0   0   2    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "3         36         1   0   0   3    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "4         36         1   0   0   4    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "...      ...       ...  ..  ..  ..    ...    ...    ...    ...    ...     ...\n",
       "5046267   35         5  43  63  59    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "5046268   35         5  43  63  60    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "5046269   35         5  43  63  61    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "5046270   35         5  43  63  62    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "5046271   35         5  43  63  63    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "\n",
       "[5046272 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=columns_mean)\n",
    "df = df.astype({\"exp\": int, \"i\": int, \"j\": int, \"k\": int, \"mini_exp\": int})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5046272 entries, 0 to 5046271\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   exp       int64  \n",
      " 1   mini_exp  int64  \n",
      " 2   i         int64  \n",
      " 3   j         int64  \n",
      " 4   k         int64  \n",
      " 5   mean0     float64\n",
      " 6   mean1     float64\n",
      " 7   mean2     float64\n",
      " 8   mean3     float64\n",
      " 9   mean4     float64\n",
      " 10  theory    float64\n",
      "dtypes: float64(6), int64(5)\n",
      "memory usage: 423.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 1. fmap mean all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_train = df[~((df['exp']==36) & ((df['mini_exp']==5) | (df['mini_exp']==6)))]\n",
    "df1_val =  df[(df['exp']==36) & (df['mini_exp']==5)]\n",
    "df1_test =  df[(df['exp']==36) & (df['mini_exp']==6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4685824, 11)\n",
      "(180224, 11)\n",
      "(180224, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df1_train.shape)\n",
    "print(df1_val.shape)\n",
    "print(df1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = df1_train.iloc[:, 5:-1].values \n",
    "y1_train = df1_train['theory'].values\n",
    "\n",
    "X1_test = df1_val.iloc[:, 5:-1].values \n",
    "y1_test = df1_val['theory'].values\n",
    "\n",
    "X1_pred = df1_test.iloc[:, 5:-1].values \n",
    "y1_pred = df1_val['theory'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4685824, 5)\n",
      "(4685824,)\n",
      "(180224, 5)\n",
      "(180224,)\n",
      "(180224, 5)\n",
      "(180224,)\n"
     ]
    }
   ],
   "source": [
    "print(X1_train.shape)\n",
    "print(y1_train.shape)\n",
    "print(X1_test.shape)\n",
    "print(y1_test.shape)\n",
    "print(X1_pred.shape)\n",
    "print(y1_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data2: One experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[(df['exp']==36) & (df['mini_exp']!=6)]\n",
    "df_test = df[(df['exp']==36) & (df['mini_exp']==6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data4: None zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonzero = df[(df['mean0']!=0.0) & (df['mean1']!=0.0) & (df['mean2']!=0.0) & (df['mean3']!=0.0) & (df['mean4']!=0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>mini_exp</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>theory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34920</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>17.758072</td>\n",
       "      <td>3.100749</td>\n",
       "      <td>-27.108955</td>\n",
       "      <td>-54.541569</td>\n",
       "      <td>-65.580933</td>\n",
       "      <td>6.323732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34921</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>-171.797119</td>\n",
       "      <td>-187.157349</td>\n",
       "      <td>-216.839035</td>\n",
       "      <td>-243.115356</td>\n",
       "      <td>-255.319305</td>\n",
       "      <td>5.692159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34922</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>-384.395447</td>\n",
       "      <td>-400.023895</td>\n",
       "      <td>-428.779266</td>\n",
       "      <td>-454.553436</td>\n",
       "      <td>-467.434479</td>\n",
       "      <td>5.156662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34923</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>-597.038513</td>\n",
       "      <td>-613.454895</td>\n",
       "      <td>-641.396118</td>\n",
       "      <td>-666.766907</td>\n",
       "      <td>-679.730591</td>\n",
       "      <td>4.694756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34959</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>-1179.840454</td>\n",
       "      <td>-1197.678955</td>\n",
       "      <td>-1222.885254</td>\n",
       "      <td>-1246.201660</td>\n",
       "      <td>-1258.513672</td>\n",
       "      <td>3.883065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003809</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>-233.451859</td>\n",
       "      <td>-219.373581</td>\n",
       "      <td>-219.398911</td>\n",
       "      <td>-222.292938</td>\n",
       "      <td>-216.633850</td>\n",
       "      <td>20.445215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003810</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>-249.901581</td>\n",
       "      <td>-236.660583</td>\n",
       "      <td>-236.275848</td>\n",
       "      <td>-238.081451</td>\n",
       "      <td>-233.357391</td>\n",
       "      <td>15.309294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003811</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>-230.639755</td>\n",
       "      <td>-218.042419</td>\n",
       "      <td>-217.110458</td>\n",
       "      <td>-218.660629</td>\n",
       "      <td>-214.294983</td>\n",
       "      <td>12.231406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003812</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>-186.973434</td>\n",
       "      <td>-174.493347</td>\n",
       "      <td>-173.302063</td>\n",
       "      <td>-174.678192</td>\n",
       "      <td>-170.903381</td>\n",
       "      <td>10.196120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003813</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>-141.898331</td>\n",
       "      <td>-129.335907</td>\n",
       "      <td>-128.347626</td>\n",
       "      <td>-130.060654</td>\n",
       "      <td>-126.084892</td>\n",
       "      <td>8.743985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748353 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         exp  mini_exp   i   j   k        mean0        mean1        mean2  \\\n",
       "34920     36         1   8  33  40    17.758072     3.100749   -27.108955   \n",
       "34921     36         1   8  33  41  -171.797119  -187.157349  -216.839035   \n",
       "34922     36         1   8  33  42  -384.395447  -400.023895  -428.779266   \n",
       "34923     36         1   8  33  43  -597.038513  -613.454895  -641.396118   \n",
       "34959     36         1   8  34  15 -1179.840454 -1197.678955 -1222.885254   \n",
       "...      ...       ...  ..  ..  ..          ...          ...          ...   \n",
       "5003809   35         5  33  40  33  -233.451859  -219.373581  -219.398911   \n",
       "5003810   35         5  33  40  34  -249.901581  -236.660583  -236.275848   \n",
       "5003811   35         5  33  40  35  -230.639755  -218.042419  -217.110458   \n",
       "5003812   35         5  33  40  36  -186.973434  -174.493347  -173.302063   \n",
       "5003813   35         5  33  40  37  -141.898331  -129.335907  -128.347626   \n",
       "\n",
       "               mean3        mean4     theory  \n",
       "34920     -54.541569   -65.580933   6.323732  \n",
       "34921    -243.115356  -255.319305   5.692159  \n",
       "34922    -454.553436  -467.434479   5.156662  \n",
       "34923    -666.766907  -679.730591   4.694756  \n",
       "34959   -1246.201660 -1258.513672   3.883065  \n",
       "...              ...          ...        ...  \n",
       "5003809  -222.292938  -216.633850  20.445215  \n",
       "5003810  -238.081451  -233.357391  15.309294  \n",
       "5003811  -218.660629  -214.294983  12.231406  \n",
       "5003812  -174.678192  -170.903381  10.196120  \n",
       "5003813  -130.060654  -126.084892   8.743985  \n",
       "\n",
       "[748353 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_train = df_nonzero[~((df_nonzero['exp']==36) & ((df_nonzero['mini_exp']==6) | (df_nonzero['mini_exp']==5)))]\n",
    "df4_test =  df_nonzero[(df_nonzero['exp']==36) & (df_nonzero['mini_exp']==5)]\n",
    "df4_pred =  df_nonzero[(df_nonzero['exp']==36) & (df_nonzero['mini_exp']==6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train = df4_train.iloc[:, 5:-1].values\n",
    "y4_train = df4_train['theory'].values\n",
    "\n",
    "X4_test = df4_test.iloc[:, 5:-1].values\n",
    "y4_test = df4_test['theory'].values\n",
    "\n",
    "X4_pred = df4_pred.iloc[:, 5:-1].values\n",
    "y4_pred = df4_pred['theory'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_nonzero.iloc[:, 5:-1].values\n",
    "# y = df_nonzero['theory'].values\n",
    "\n",
    "# X4_train, X4_test, y4_train, y4_test = train_test_split(\n",
    "#     X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(694168, 5)\n",
      "(694168,)\n",
      "(27092, 5)\n",
      "(27092,)\n",
      "(27093, 5)\n",
      "(27093,)\n"
     ]
    }
   ],
   "source": [
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "print(X4_train.shape)\n",
    "print(y4_train.shape)\n",
    "print(X4_test.shape)\n",
    "print(y4_test.shape)\n",
    "print(X4_pred.shape)\n",
    "print(y4_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include zero 32 to 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X1_train\n",
    "y_train = y1_train\n",
    "X_test = X1_test\n",
    "y_test = y1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (len(X_train[0]),)\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=shape)) \n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adamax', loss='mse', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "146432/146432 [==============================] - 151s 1ms/step - loss: 36.2151 - accuracy: 0.6203 - val_loss: 9.9205 - val_accuracy: 0.8495\n",
      "Epoch 2/100\n",
      "146432/146432 [==============================] - 144s 983us/step - loss: 5.7961 - accuracy: 0.8515 - val_loss: 6.5620 - val_accuracy: 0.8495\n",
      "Epoch 3/100\n",
      "146432/146432 [==============================] - 1914s 13ms/step - loss: 5.0681 - accuracy: 0.8515 - val_loss: 5.7479 - val_accuracy: 0.8496\n",
      "Epoch 4/100\n",
      "146432/146432 [==============================] - 1974s 13ms/step - loss: 4.8988 - accuracy: 0.8515 - val_loss: 4.3896 - val_accuracy: 0.8496\n",
      "Epoch 5/100\n",
      "146188/146432 [============================>.] - ETA: 1s - loss: 4.8279 - accuracy: 0.8515"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "print(mse(train_pred, y_train))\n",
    "print(mape(train_pred, y_train))\n",
    "test_pred = model.predict(X_test)\n",
    "print(mse(test_pred, y_test))\n",
    "print(mape(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(test_pred.flatten(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = img_path+'model_32to38_erode.sav'\n",
    "pickle.dump(model, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 1s 842us/step - loss: 56.8737 - accuracy: 8.8204e-04\n",
      "[56.87367630004883, 0.0008820416405797005]\n"
     ]
    }
   ],
   "source": [
    "load_model = pickle.load(open(file, 'rb'))\n",
    "result = load_model.evaluate(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_df = pd.DataFrame(history.history)\n",
    "model_df[['loss', 'val_loss']].plot()\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Training Period\", pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[['accuracy', 'val_accuracy']].plot()\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuray Over Training Period\", pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory vs Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = y_test.flatten()\n",
    "y = test_pred.flatten()\n",
    "m, b, r, p, st_er = stats.linregress(x,y) \n",
    "\n",
    "yfit = [b + m * xi for xi in x]\n",
    "yisx = [0 + 1 * xi for xi in x]\n",
    "plt.plot(x, yfit)\n",
    "plt.plot(x, yisx)\n",
    "\n",
    "plt.scatter(y_test, test_pred,  color='black')\n",
    "plt.axis([0,100, 0, 100])\n",
    "plt.xlabel(\"Theory (nT)\")\n",
    "plt.ylabel(\"Prediction (nT)\")\n",
    "plt.title(\"Neural Network Prediction vs Theory\", fontsize=15)\n",
    "# print(r, st_er)\n",
    "print(\"r: {:.5f}, st_er: {:.6f}\".format(r, st_er))\n",
    "print(\"y = \"+str(round(m,4))+\"*x + \"+str(round(b,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test['predict'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(img_path+\"nn_32to38_erode.txt\", df_test[['i', 'j', 'k', 'predict']], fmt=\"%i %i %i %s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonzero 32 to 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X4_train\n",
    "y_train = y4_train\n",
    "X_test = X4_test\n",
    "y_test = y4_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 10:36:54.463240: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "shape = (len(X_train[0]),)\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(5, activation='relu', input_shape=shape)) \n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='RMSprop', loss='mse', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10847/10847 [==============================] - 11s 987us/step - loss: 133.6451 - accuracy: 1.5126e-04 - val_loss: 57.3660 - val_accuracy: 3.6911e-04\n",
      "Epoch 2/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 39.0951 - accuracy: 3.0108e-04 - val_loss: 48.1437 - val_accuracy: 9.5969e-04\n",
      "Epoch 3/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 33.2156 - accuracy: 5.7335e-04 - val_loss: 39.2433 - val_accuracy: 0.0010\n",
      "Epoch 4/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 31.5992 - accuracy: 6.3529e-04 - val_loss: 38.5932 - val_accuracy: 0.0013\n",
      "Epoch 5/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 31.0795 - accuracy: 6.5258e-04 - val_loss: 34.6038 - val_accuracy: 0.0010\n",
      "Epoch 6/1000\n",
      "10847/10847 [==============================] - 11s 986us/step - loss: 31.1943 - accuracy: 6.3385e-04 - val_loss: 39.4543 - val_accuracy: 0.0016\n",
      "Epoch 7/1000\n",
      "10847/10847 [==============================] - 11s 981us/step - loss: 31.2799 - accuracy: 6.1657e-04 - val_loss: 40.9862 - val_accuracy: 0.0032\n",
      "Epoch 8/1000\n",
      "10847/10847 [==============================] - 10s 962us/step - loss: 31.9815 - accuracy: 6.2089e-04 - val_loss: 33.3671 - val_accuracy: 0.0010\n",
      "Epoch 9/1000\n",
      "10847/10847 [==============================] - 11s 974us/step - loss: 32.1609 - accuracy: 5.5750e-04 - val_loss: 30.7978 - val_accuracy: 0.0010\n",
      "Epoch 10/1000\n",
      "10847/10847 [==============================] - 10s 945us/step - loss: 32.0396 - accuracy: 5.0852e-04 - val_loss: 42.0681 - val_accuracy: 1.8456e-04\n",
      "Epoch 11/1000\n",
      "10847/10847 [==============================] - 10s 943us/step - loss: 32.1880 - accuracy: 4.8835e-04 - val_loss: 29.6390 - val_accuracy: 2.5838e-04\n",
      "Epoch 12/1000\n",
      "10847/10847 [==============================] - 11s 982us/step - loss: 31.0274 - accuracy: 5.2869e-04 - val_loss: 24.5893 - val_accuracy: 0.0031\n",
      "Epoch 13/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 30.1540 - accuracy: 5.0852e-04 - val_loss: 28.2982 - val_accuracy: 0.0033\n",
      "Epoch 14/1000\n",
      "10847/10847 [==============================] - 11s 990us/step - loss: 30.2864 - accuracy: 5.0708e-04 - val_loss: 33.9960 - val_accuracy: 1.4765e-04\n",
      "Epoch 15/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 30.0692 - accuracy: 5.2437e-04 - val_loss: 26.3487 - val_accuracy: 0.0010\n",
      "Epoch 16/1000\n",
      "10847/10847 [==============================] - 11s 968us/step - loss: 30.0472 - accuracy: 5.4022e-04 - val_loss: 28.1064 - val_accuracy: 0.0010\n",
      "Epoch 17/1000\n",
      "10847/10847 [==============================] - 10s 966us/step - loss: 30.0621 - accuracy: 5.4742e-04 - val_loss: 27.7096 - val_accuracy: 0.0014\n",
      "Epoch 18/1000\n",
      "10847/10847 [==============================] - 10s 954us/step - loss: 30.1491 - accuracy: 5.4166e-04 - val_loss: 28.1609 - val_accuracy: 1.8456e-04\n",
      "Epoch 19/1000\n",
      "10847/10847 [==============================] - 11s 999us/step - loss: 30.1634 - accuracy: 5.5318e-04 - val_loss: 40.9641 - val_accuracy: 0.0013\n",
      "Epoch 20/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 30.0045 - accuracy: 5.9928e-04 - val_loss: 23.1263 - val_accuracy: 3.3220e-04\n",
      "Epoch 21/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 30.1799 - accuracy: 6.3817e-04 - val_loss: 31.9671 - val_accuracy: 0.0029\n",
      "Epoch 22/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 29.9615 - accuracy: 6.2953e-04 - val_loss: 29.1205 - val_accuracy: 0.0011\n",
      "Epoch 23/1000\n",
      "10847/10847 [==============================] - 10s 966us/step - loss: 29.7832 - accuracy: 6.7131e-04 - val_loss: 24.1766 - val_accuracy: 3.3220e-04\n",
      "Epoch 24/1000\n",
      "10847/10847 [==============================] - 11s 994us/step - loss: 29.6369 - accuracy: 6.7419e-04 - val_loss: 31.2610 - val_accuracy: 0.0015\n",
      "Epoch 25/1000\n",
      "10847/10847 [==============================] - 10s 937us/step - loss: 29.5295 - accuracy: 6.7419e-04 - val_loss: 25.5126 - val_accuracy: 7.3823e-04\n",
      "Epoch 26/1000\n",
      "10847/10847 [==============================] - 11s 995us/step - loss: 29.4049 - accuracy: 6.4826e-04 - val_loss: 32.7236 - val_accuracy: 0.0011\n",
      "Epoch 27/1000\n",
      "10847/10847 [==============================] - 10s 965us/step - loss: 29.3643 - accuracy: 6.6987e-04 - val_loss: 25.3437 - val_accuracy: 0.0011\n",
      "Epoch 28/1000\n",
      "10847/10847 [==============================] - 10s 967us/step - loss: 29.2243 - accuracy: 6.0936e-04 - val_loss: 32.8938 - val_accuracy: 2.5838e-04\n",
      "Epoch 29/1000\n",
      "10847/10847 [==============================] - 11s 982us/step - loss: 29.2147 - accuracy: 6.2233e-04 - val_loss: 30.7448 - val_accuracy: 0.0019\n",
      "Epoch 30/1000\n",
      "10847/10847 [==============================] - 10s 937us/step - loss: 29.1003 - accuracy: 6.4106e-04 - val_loss: 29.9321 - val_accuracy: 0.0015\n",
      "Epoch 31/1000\n",
      "10847/10847 [==============================] - 10s 952us/step - loss: 29.0871 - accuracy: 5.9064e-04 - val_loss: 27.9854 - val_accuracy: 1.1073e-04\n",
      "Epoch 32/1000\n",
      "10847/10847 [==============================] - 10s 905us/step - loss: 29.0313 - accuracy: 5.9496e-04 - val_loss: 32.1850 - val_accuracy: 0.0015\n",
      "Epoch 33/1000\n",
      "10847/10847 [==============================] - 10s 917us/step - loss: 28.8840 - accuracy: 6.1080e-04 - val_loss: 29.3435 - val_accuracy: 2.5838e-04\n",
      "Epoch 34/1000\n",
      "10847/10847 [==============================] - 10s 905us/step - loss: 28.9169 - accuracy: 5.8199e-04 - val_loss: 30.8653 - val_accuracy: 0.0015\n",
      "Epoch 35/1000\n",
      "10847/10847 [==============================] - 10s 954us/step - loss: 28.7984 - accuracy: 5.2437e-04 - val_loss: 29.3894 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "10847/10847 [==============================] - 10s 946us/step - loss: 28.9011 - accuracy: 5.4598e-04 - val_loss: 35.5318 - val_accuracy: 3.6911e-04\n",
      "Epoch 37/1000\n",
      "10847/10847 [==============================] - 10s 958us/step - loss: 28.7713 - accuracy: 5.2581e-04 - val_loss: 35.7130 - val_accuracy: 3.6911e-04\n",
      "Epoch 38/1000\n",
      "10847/10847 [==============================] - 10s 921us/step - loss: 28.7643 - accuracy: 5.4742e-04 - val_loss: 31.1545 - val_accuracy: 0.0023\n",
      "Epoch 39/1000\n",
      "10847/10847 [==============================] - 10s 968us/step - loss: 28.7376 - accuracy: 5.3445e-04 - val_loss: 27.7518 - val_accuracy: 1.8456e-04\n",
      "Epoch 40/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 28.7003 - accuracy: 5.0276e-04 - val_loss: 26.6580 - val_accuracy: 3.6911e-04\n",
      "Epoch 41/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 28.6467 - accuracy: 4.7827e-04 - val_loss: 25.5554 - val_accuracy: 3.6911e-04\n",
      "Epoch 42/1000\n",
      "10847/10847 [==============================] - 10s 956us/step - loss: 28.5946 - accuracy: 4.4226e-04 - val_loss: 25.4852 - val_accuracy: 0.0015\n",
      "Epoch 43/1000\n",
      "10847/10847 [==============================] - 10s 930us/step - loss: 28.5683 - accuracy: 4.3505e-04 - val_loss: 35.3671 - val_accuracy: 3.6911e-04\n",
      "Epoch 44/1000\n",
      "10847/10847 [==============================] - 10s 890us/step - loss: 28.5707 - accuracy: 4.3361e-04 - val_loss: 31.8760 - val_accuracy: 3.6911e-04\n",
      "Epoch 45/1000\n",
      "10847/10847 [==============================] - 10s 905us/step - loss: 28.5224 - accuracy: 3.9184e-04 - val_loss: 22.2218 - val_accuracy: 0.0015\n",
      "Epoch 46/1000\n",
      "10847/10847 [==============================] - 10s 956us/step - loss: 28.5064 - accuracy: 4.3937e-04 - val_loss: 23.1826 - val_accuracy: 3.6911e-04\n",
      "Epoch 47/1000\n",
      "10847/10847 [==============================] - 10s 903us/step - loss: 28.4745 - accuracy: 4.3217e-04 - val_loss: 25.5314 - val_accuracy: 1.8456e-04\n",
      "Epoch 48/1000\n",
      "10847/10847 [==============================] - 10s 962us/step - loss: 28.4341 - accuracy: 4.1344e-04 - val_loss: 32.7458 - val_accuracy: 0.0013\n",
      "Epoch 49/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 28.4256 - accuracy: 4.3361e-04 - val_loss: 22.8466 - val_accuracy: 1.1073e-04\n",
      "Epoch 50/1000\n",
      "10847/10847 [==============================] - 10s 917us/step - loss: 28.4275 - accuracy: 4.0048e-04 - val_loss: 24.7910 - val_accuracy: 0.0016\n",
      "Epoch 51/1000\n",
      "10847/10847 [==============================] - 10s 923us/step - loss: 28.3771 - accuracy: 4.1633e-04 - val_loss: 23.0612 - val_accuracy: 7.7514e-04\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 10s 919us/step - loss: 28.3399 - accuracy: 3.9040e-04 - val_loss: 22.8478 - val_accuracy: 7.7514e-04\n",
      "Epoch 53/1000\n",
      "10847/10847 [==============================] - 10s 919us/step - loss: 28.3362 - accuracy: 3.9616e-04 - val_loss: 23.8701 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "10847/10847 [==============================] - 10s 896us/step - loss: 28.2607 - accuracy: 3.6014e-04 - val_loss: 37.0438 - val_accuracy: 1.8456e-04\n",
      "Epoch 55/1000\n",
      "10847/10847 [==============================] - 10s 931us/step - loss: 28.3407 - accuracy: 4.1777e-04 - val_loss: 26.8361 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "10847/10847 [==============================] - 10s 897us/step - loss: 28.2885 - accuracy: 3.6158e-04 - val_loss: 25.7970 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "10847/10847 [==============================] - 10s 918us/step - loss: 28.1569 - accuracy: 3.8895e-04 - val_loss: 23.0824 - val_accuracy: 1.1073e-04\n",
      "Epoch 58/1000\n",
      "10847/10847 [==============================] - 10s 956us/step - loss: 28.1592 - accuracy: 4.0912e-04 - val_loss: 26.0618 - val_accuracy: 1.1073e-04\n",
      "Epoch 59/1000\n",
      "10847/10847 [==============================] - 10s 930us/step - loss: 28.1379 - accuracy: 4.0480e-04 - val_loss: 22.2574 - val_accuracy: 6.6440e-04\n",
      "Epoch 60/1000\n",
      "10847/10847 [==============================] - 10s 920us/step - loss: 28.1372 - accuracy: 3.9040e-04 - val_loss: 22.1623 - val_accuracy: 6.6440e-04\n",
      "Epoch 61/1000\n",
      "10847/10847 [==============================] - 10s 911us/step - loss: 28.0942 - accuracy: 3.8031e-04 - val_loss: 22.6999 - val_accuracy: 9.5969e-04\n",
      "Epoch 62/1000\n",
      "10847/10847 [==============================] - 10s 937us/step - loss: 28.1117 - accuracy: 3.9904e-04 - val_loss: 21.7059 - val_accuracy: 7.7514e-04\n",
      "Epoch 63/1000\n",
      "10847/10847 [==============================] - 10s 951us/step - loss: 28.0581 - accuracy: 4.3073e-04 - val_loss: 25.8062 - val_accuracy: 6.6440e-04\n",
      "Epoch 64/1000\n",
      "10847/10847 [==============================] - 10s 929us/step - loss: 28.0223 - accuracy: 4.3361e-04 - val_loss: 22.9554 - val_accuracy: 0.0016\n",
      "Epoch 65/1000\n",
      "10847/10847 [==============================] - 10s 882us/step - loss: 28.0716 - accuracy: 4.6242e-04 - val_loss: 27.2485 - val_accuracy: 0.0019\n",
      "Epoch 66/1000\n",
      "10847/10847 [==============================] - 10s 895us/step - loss: 28.0486 - accuracy: 4.5378e-04 - val_loss: 25.9039 - val_accuracy: 0.0016\n",
      "Epoch 67/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 28.0039 - accuracy: 4.5234e-04 - val_loss: 22.0803 - val_accuracy: 7.7514e-04\n",
      "Epoch 68/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 27.9851 - accuracy: 4.8835e-04 - val_loss: 20.2642 - val_accuracy: 3.6911e-05\n",
      "Epoch 69/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 27.9692 - accuracy: 4.8691e-04 - val_loss: 22.5798 - val_accuracy: 7.7514e-04\n",
      "Epoch 70/1000\n",
      "10847/10847 [==============================] - 10s 881us/step - loss: 28.0077 - accuracy: 4.8691e-04 - val_loss: 28.1394 - val_accuracy: 7.7514e-04\n",
      "Epoch 71/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 27.9755 - accuracy: 4.5378e-04 - val_loss: 26.2821 - val_accuracy: 0.0016\n",
      "Epoch 72/1000\n",
      "10847/10847 [==============================] - 9s 875us/step - loss: 27.9752 - accuracy: 4.7827e-04 - val_loss: 23.2968 - val_accuracy: 0.0021\n",
      "Epoch 73/1000\n",
      "10847/10847 [==============================] - 9s 873us/step - loss: 27.9992 - accuracy: 5.1717e-04 - val_loss: 22.3453 - val_accuracy: 0.0016\n",
      "Epoch 74/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 27.9444 - accuracy: 4.7395e-04 - val_loss: 23.0476 - val_accuracy: 6.6440e-04\n",
      "Epoch 75/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 27.8889 - accuracy: 5.1284e-04 - val_loss: 22.5773 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 27.9310 - accuracy: 5.0708e-04 - val_loss: 22.0386 - val_accuracy: 0.0016\n",
      "Epoch 77/1000\n",
      "10847/10847 [==============================] - 10s 876us/step - loss: 27.9085 - accuracy: 4.9412e-04 - val_loss: 24.3266 - val_accuracy: 5.9058e-04\n",
      "Epoch 78/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 27.9363 - accuracy: 4.7539e-04 - val_loss: 21.1079 - val_accuracy: 7.7514e-04\n",
      "Epoch 79/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 27.9218 - accuracy: 4.7395e-04 - val_loss: 22.1413 - val_accuracy: 6.6440e-04\n",
      "Epoch 80/1000\n",
      "10847/10847 [==============================] - 10s 878us/step - loss: 27.9604 - accuracy: 5.2149e-04 - val_loss: 22.0518 - val_accuracy: 5.1676e-04\n",
      "Epoch 81/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 27.9325 - accuracy: 4.7683e-04 - val_loss: 23.4211 - val_accuracy: 0.0016\n",
      "Epoch 82/1000\n",
      "10847/10847 [==============================] - 10s 879us/step - loss: 27.9346 - accuracy: 4.8835e-04 - val_loss: 23.8369 - val_accuracy: 0.0016\n",
      "Epoch 83/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 27.9134 - accuracy: 4.9412e-04 - val_loss: 26.2086 - val_accuracy: 7.7514e-04\n",
      "Epoch 84/1000\n",
      "10847/10847 [==============================] - 9s 873us/step - loss: 27.9138 - accuracy: 4.7683e-04 - val_loss: 28.4532 - val_accuracy: 5.9058e-04\n",
      "Epoch 85/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 27.9375 - accuracy: 5.1140e-04 - val_loss: 20.5376 - val_accuracy: 5.1676e-04\n",
      "Epoch 86/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 27.8812 - accuracy: 5.0132e-04 - val_loss: 27.1108 - val_accuracy: 4.7985e-04\n",
      "Epoch 87/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 27.9117 - accuracy: 4.9988e-04 - val_loss: 21.9341 - val_accuracy: 0.0013\n",
      "Epoch 88/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 27.8470 - accuracy: 4.8979e-04 - val_loss: 25.1973 - val_accuracy: 5.1676e-04\n",
      "Epoch 89/1000\n",
      "10847/10847 [==============================] - 10s 876us/step - loss: 27.8440 - accuracy: 4.8979e-04 - val_loss: 23.9522 - val_accuracy: 1.1073e-04\n",
      "Epoch 90/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 27.8531 - accuracy: 4.9988e-04 - val_loss: 33.0782 - val_accuracy: 0.0016\n",
      "Epoch 91/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 27.8378 - accuracy: 4.9556e-04 - val_loss: 20.8132 - val_accuracy: 3.6911e-05\n",
      "Epoch 92/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 27.7446 - accuracy: 4.7683e-04 - val_loss: 21.2226 - val_accuracy: 2.5838e-04\n",
      "Epoch 93/1000\n",
      "10847/10847 [==============================] - 9s 875us/step - loss: 27.7852 - accuracy: 4.9844e-04 - val_loss: 20.0949 - val_accuracy: 6.6440e-04\n",
      "Epoch 94/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 27.7333 - accuracy: 4.5522e-04 - val_loss: 26.1243 - val_accuracy: 0.0016\n",
      "Epoch 95/1000\n",
      "10847/10847 [==============================] - 9s 873us/step - loss: 27.6947 - accuracy: 4.5522e-04 - val_loss: 22.9038 - val_accuracy: 2.9529e-04\n",
      "Epoch 96/1000\n",
      "10847/10847 [==============================] - 9s 874us/step - loss: 27.7043 - accuracy: 4.5666e-04 - val_loss: 19.7452 - val_accuracy: 2.9529e-04\n",
      "Epoch 97/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 27.6574 - accuracy: 4.6531e-04 - val_loss: 23.0871 - val_accuracy: 1.4765e-04\n",
      "Epoch 98/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 27.6572 - accuracy: 4.1921e-04 - val_loss: 27.8515 - val_accuracy: 2.9529e-04\n",
      "Epoch 99/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 27.6575 - accuracy: 4.3073e-04 - val_loss: 21.4304 - val_accuracy: 2.9529e-04\n",
      "Epoch 100/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 27.5958 - accuracy: 4.4082e-04 - val_loss: 22.0515 - val_accuracy: 0.0012\n",
      "Epoch 101/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 27.5721 - accuracy: 4.0768e-04 - val_loss: 27.3027 - val_accuracy: 1.8456e-04\n",
      "Epoch 102/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 27.5532 - accuracy: 4.0048e-04 - val_loss: 20.6964 - val_accuracy: 1.4765e-04\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 9s 868us/step - loss: 27.5960 - accuracy: 3.9184e-04 - val_loss: 32.2959 - val_accuracy: 0.0011\n",
      "Epoch 104/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 27.5380 - accuracy: 3.9472e-04 - val_loss: 18.3590 - val_accuracy: 1.8456e-04\n",
      "Epoch 105/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 27.5377 - accuracy: 3.9616e-04 - val_loss: 23.9899 - val_accuracy: 2.9529e-04\n",
      "Epoch 106/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 27.4888 - accuracy: 3.7023e-04 - val_loss: 18.3584 - val_accuracy: 1.4765e-04\n",
      "Epoch 107/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 27.4512 - accuracy: 4.2497e-04 - val_loss: 20.2381 - val_accuracy: 1.4765e-04\n",
      "Epoch 108/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 27.5121 - accuracy: 3.7455e-04 - val_loss: 18.3072 - val_accuracy: 1.4765e-04\n",
      "Epoch 109/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 27.4779 - accuracy: 4.2785e-04 - val_loss: 23.2419 - val_accuracy: 1.4765e-04\n",
      "Epoch 110/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 27.4501 - accuracy: 3.7743e-04 - val_loss: 20.3779 - val_accuracy: 3.3220e-04\n",
      "Epoch 111/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 27.4097 - accuracy: 4.0192e-04 - val_loss: 23.5099 - val_accuracy: 0.0012\n",
      "Epoch 112/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 27.4065 - accuracy: 3.8175e-04 - val_loss: 22.2182 - val_accuracy: 0.0014\n",
      "Epoch 113/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 27.4398 - accuracy: 3.5582e-04 - val_loss: 19.7496 - val_accuracy: 1.4765e-04\n",
      "Epoch 114/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 27.4037 - accuracy: 3.5438e-04 - val_loss: 21.1025 - val_accuracy: 0.0014\n",
      "Epoch 115/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 27.4108 - accuracy: 3.8031e-04 - val_loss: 22.0343 - val_accuracy: 1.4765e-04\n",
      "Epoch 116/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 27.4194 - accuracy: 3.8895e-04 - val_loss: 23.6883 - val_accuracy: 6.6440e-04\n",
      "Epoch 117/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 27.3742 - accuracy: 3.6302e-04 - val_loss: 19.1102 - val_accuracy: 1.4765e-04\n",
      "Epoch 118/1000\n",
      "10847/10847 [==============================] - 10s 900us/step - loss: 27.4363 - accuracy: 3.9040e-04 - val_loss: 20.5180 - val_accuracy: 5.9058e-04\n",
      "Epoch 119/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 27.4529 - accuracy: 3.6879e-04 - val_loss: 20.8527 - val_accuracy: 1.8456e-04\n",
      "Epoch 120/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 27.3586 - accuracy: 3.6447e-04 - val_loss: 20.5102 - val_accuracy: 5.1676e-04\n",
      "Epoch 121/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 27.5064 - accuracy: 3.9184e-04 - val_loss: 21.1353 - val_accuracy: 1.1073e-04\n",
      "Epoch 122/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 27.4248 - accuracy: 3.7743e-04 - val_loss: 22.1804 - val_accuracy: 7.3823e-05\n",
      "Epoch 123/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 27.5126 - accuracy: 3.7167e-04 - val_loss: 21.9024 - val_accuracy: 5.9058e-04\n",
      "Epoch 124/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 27.5658 - accuracy: 3.6302e-04 - val_loss: 30.9037 - val_accuracy: 0.0023\n",
      "Epoch 125/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 27.4672 - accuracy: 3.7167e-04 - val_loss: 28.3520 - val_accuracy: 0.0010\n",
      "Epoch 126/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 27.4722 - accuracy: 3.8751e-04 - val_loss: 26.4807 - val_accuracy: 0.0014\n",
      "Epoch 127/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 27.7963 - accuracy: 3.4862e-04 - val_loss: 22.1694 - val_accuracy: 5.5367e-04\n",
      "Epoch 128/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 27.7422 - accuracy: 3.1116e-04 - val_loss: 27.7346 - val_accuracy: 7.3823e-05\n",
      "Epoch 129/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 27.8420 - accuracy: 3.0828e-04 - val_loss: 33.1913 - val_accuracy: 4.7985e-04\n",
      "Epoch 130/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 27.7649 - accuracy: 3.0972e-04 - val_loss: 48.2690 - val_accuracy: 0.0020\n",
      "Epoch 131/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 27.7091 - accuracy: 3.0828e-04 - val_loss: 27.7936 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 27.8750 - accuracy: 3.1837e-04 - val_loss: 39.3461 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 28.0571 - accuracy: 2.5930e-04 - val_loss: 29.3195 - val_accuracy: 5.1676e-04\n",
      "Epoch 134/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 28.2473 - accuracy: 2.2617e-04 - val_loss: 22.8811 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 28.2324 - accuracy: 2.4634e-04 - val_loss: 29.2518 - val_accuracy: 4.7985e-04\n",
      "Epoch 136/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 28.2832 - accuracy: 2.3625e-04 - val_loss: 19.6573 - val_accuracy: 7.3823e-05\n",
      "Epoch 137/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 27.9145 - accuracy: 2.2617e-04 - val_loss: 21.1450 - val_accuracy: 4.4294e-04\n",
      "Epoch 138/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 27.7571 - accuracy: 2.5642e-04 - val_loss: 21.9359 - val_accuracy: 7.3823e-05\n",
      "Epoch 139/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 27.6285 - accuracy: 2.2761e-04 - val_loss: 23.9742 - val_accuracy: 4.4294e-04\n",
      "Epoch 140/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 27.5765 - accuracy: 2.8091e-04 - val_loss: 21.5887 - val_accuracy: 7.3823e-05\n",
      "Epoch 141/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 27.4930 - accuracy: 2.7803e-04 - val_loss: 19.6885 - val_accuracy: 4.4294e-04\n",
      "Epoch 142/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 27.4204 - accuracy: 2.7083e-04 - val_loss: 21.2285 - val_accuracy: 7.3823e-05\n",
      "Epoch 143/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 27.3482 - accuracy: 2.6362e-04 - val_loss: 20.7847 - val_accuracy: 4.7985e-04\n",
      "Epoch 144/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 27.2974 - accuracy: 2.9820e-04 - val_loss: 20.8477 - val_accuracy: 4.4294e-04\n",
      "Epoch 145/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 27.2459 - accuracy: 2.8811e-04 - val_loss: 21.7732 - val_accuracy: 4.7985e-04\n",
      "Epoch 146/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 27.1762 - accuracy: 2.9244e-04 - val_loss: 18.9214 - val_accuracy: 0.0013\n",
      "Epoch 147/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 27.1613 - accuracy: 2.7947e-04 - val_loss: 19.9265 - val_accuracy: 3.6911e-05\n",
      "Epoch 148/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 27.1043 - accuracy: 2.9100e-04 - val_loss: 20.3553 - val_accuracy: 4.4294e-04\n",
      "Epoch 149/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 27.0492 - accuracy: 2.9820e-04 - val_loss: 19.8428 - val_accuracy: 7.3823e-05\n",
      "Epoch 150/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 27.0002 - accuracy: 3.2845e-04 - val_loss: 18.1962 - val_accuracy: 3.6911e-05\n",
      "Epoch 151/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 27.0136 - accuracy: 3.0108e-04 - val_loss: 18.4329 - val_accuracy: 4.0602e-04\n",
      "Epoch 152/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 26.9686 - accuracy: 2.9964e-04 - val_loss: 17.1797 - val_accuracy: 3.6911e-05\n",
      "Epoch 153/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 26.9118 - accuracy: 3.1981e-04 - val_loss: 20.7499 - val_accuracy: 1.1073e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 26.9098 - accuracy: 2.9820e-04 - val_loss: 17.3487 - val_accuracy: 3.6911e-05\n",
      "Epoch 155/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 26.8980 - accuracy: 3.1260e-04 - val_loss: 18.8743 - val_accuracy: 4.7985e-04\n",
      "Epoch 156/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.8701 - accuracy: 3.2989e-04 - val_loss: 17.0919 - val_accuracy: 3.6911e-05\n",
      "Epoch 157/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 26.8457 - accuracy: 2.9820e-04 - val_loss: 20.2183 - val_accuracy: 4.4294e-04\n",
      "Epoch 158/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 26.8122 - accuracy: 2.9820e-04 - val_loss: 19.5702 - val_accuracy: 4.4294e-04\n",
      "Epoch 159/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 26.8171 - accuracy: 3.0540e-04 - val_loss: 18.6185 - val_accuracy: 4.0602e-04\n",
      "Epoch 160/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 26.7713 - accuracy: 2.8667e-04 - val_loss: 18.9166 - val_accuracy: 4.7985e-04\n",
      "Epoch 161/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.7891 - accuracy: 3.0972e-04 - val_loss: 19.9746 - val_accuracy: 3.6911e-05\n",
      "Epoch 162/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.7668 - accuracy: 2.8523e-04 - val_loss: 19.1162 - val_accuracy: 4.4294e-04\n",
      "Epoch 163/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 26.7378 - accuracy: 2.9388e-04 - val_loss: 21.0283 - val_accuracy: 0.0013\n",
      "Epoch 164/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.7031 - accuracy: 2.7947e-04 - val_loss: 19.4633 - val_accuracy: 1.1073e-04\n",
      "Epoch 165/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 26.7244 - accuracy: 3.2701e-04 - val_loss: 20.6669 - val_accuracy: 3.6911e-05\n",
      "Epoch 166/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 26.6862 - accuracy: 2.9244e-04 - val_loss: 20.1465 - val_accuracy: 0.0013\n",
      "Epoch 167/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.7006 - accuracy: 3.0252e-04 - val_loss: 18.3526 - val_accuracy: 3.6911e-04\n",
      "Epoch 168/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 26.6726 - accuracy: 2.9388e-04 - val_loss: 19.3899 - val_accuracy: 0.0013\n",
      "Epoch 169/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 26.6503 - accuracy: 2.8091e-04 - val_loss: 22.4399 - val_accuracy: 0.0028\n",
      "Epoch 170/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 26.6453 - accuracy: 3.1693e-04 - val_loss: 21.0405 - val_accuracy: 9.5969e-04\n",
      "Epoch 171/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 26.6259 - accuracy: 2.8379e-04 - val_loss: 20.7219 - val_accuracy: 0.0028\n",
      "Epoch 172/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 26.5988 - accuracy: 2.9964e-04 - val_loss: 19.1337 - val_accuracy: 3.6911e-05\n",
      "Epoch 173/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 26.6147 - accuracy: 2.8235e-04 - val_loss: 18.0005 - val_accuracy: 4.4294e-04\n",
      "Epoch 174/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 26.6132 - accuracy: 2.7803e-04 - val_loss: 19.2474 - val_accuracy: 4.7985e-04\n",
      "Epoch 175/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 26.5917 - accuracy: 2.8956e-04 - val_loss: 17.9944 - val_accuracy: 3.6911e-05\n",
      "Epoch 176/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.5940 - accuracy: 2.7947e-04 - val_loss: 21.8145 - val_accuracy: 4.7985e-04\n",
      "Epoch 177/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 26.5728 - accuracy: 2.8235e-04 - val_loss: 18.8429 - val_accuracy: 4.7985e-04\n",
      "Epoch 178/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 26.5774 - accuracy: 2.7947e-04 - val_loss: 17.0366 - val_accuracy: 3.6911e-05\n",
      "Epoch 179/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 26.5520 - accuracy: 2.5498e-04 - val_loss: 19.0018 - val_accuracy: 3.6911e-05\n",
      "Epoch 180/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.5546 - accuracy: 2.4778e-04 - val_loss: 19.9240 - val_accuracy: 0.0013\n",
      "Epoch 181/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.5256 - accuracy: 2.7803e-04 - val_loss: 18.8723 - val_accuracy: 3.6911e-05\n",
      "Epoch 182/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 26.4895 - accuracy: 2.4490e-04 - val_loss: 17.0761 - val_accuracy: 3.6911e-05\n",
      "Epoch 183/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.5017 - accuracy: 2.4490e-04 - val_loss: 18.0850 - val_accuracy: 3.6911e-05\n",
      "Epoch 184/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 26.4970 - accuracy: 2.8235e-04 - val_loss: 19.1531 - val_accuracy: 7.3823e-05\n",
      "Epoch 185/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 26.4840 - accuracy: 2.6074e-04 - val_loss: 19.0652 - val_accuracy: 0.0013\n",
      "Epoch 186/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 26.4858 - accuracy: 2.5498e-04 - val_loss: 16.9778 - val_accuracy: 4.0602e-04\n",
      "Epoch 187/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 26.4925 - accuracy: 2.4490e-04 - val_loss: 17.8245 - val_accuracy: 4.0602e-04\n",
      "Epoch 188/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 26.4634 - accuracy: 2.3914e-04 - val_loss: 18.6643 - val_accuracy: 3.6911e-05\n",
      "Epoch 189/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.4656 - accuracy: 2.5354e-04 - val_loss: 17.3934 - val_accuracy: 4.0602e-04\n",
      "Epoch 190/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.4581 - accuracy: 2.4922e-04 - val_loss: 18.1865 - val_accuracy: 7.3823e-05\n",
      "Epoch 191/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.4328 - accuracy: 2.8091e-04 - val_loss: 16.2680 - val_accuracy: 3.6911e-05\n",
      "Epoch 192/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 26.4216 - accuracy: 2.5642e-04 - val_loss: 18.1327 - val_accuracy: 3.6911e-05\n",
      "Epoch 193/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 26.4117 - accuracy: 2.2473e-04 - val_loss: 17.6483 - val_accuracy: 3.6911e-05\n",
      "Epoch 194/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.4144 - accuracy: 2.4922e-04 - val_loss: 18.9537 - val_accuracy: 7.3823e-05\n",
      "Epoch 195/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.3833 - accuracy: 2.6074e-04 - val_loss: 18.9436 - val_accuracy: 3.6911e-05\n",
      "Epoch 196/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.3883 - accuracy: 2.2329e-04 - val_loss: 18.9796 - val_accuracy: 4.4294e-04\n",
      "Epoch 197/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 26.3798 - accuracy: 2.5066e-04 - val_loss: 17.9299 - val_accuracy: 4.0602e-04\n",
      "Epoch 198/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 26.3856 - accuracy: 2.2041e-04 - val_loss: 17.7922 - val_accuracy: 4.0602e-04\n",
      "Epoch 199/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 26.3521 - accuracy: 2.4634e-04 - val_loss: 17.9851 - val_accuracy: 4.0602e-04\n",
      "Epoch 200/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.3687 - accuracy: 2.4346e-04 - val_loss: 18.9841 - val_accuracy: 4.0602e-04\n",
      "Epoch 201/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 26.3759 - accuracy: 2.5930e-04 - val_loss: 17.9018 - val_accuracy: 3.6911e-05\n",
      "Epoch 202/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.3741 - accuracy: 2.2473e-04 - val_loss: 16.7033 - val_accuracy: 4.4294e-04\n",
      "Epoch 203/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.3361 - accuracy: 2.2329e-04 - val_loss: 18.1899 - val_accuracy: 3.6911e-05\n",
      "Epoch 204/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.3249 - accuracy: 2.4634e-04 - val_loss: 16.3027 - val_accuracy: 3.6911e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 26.3311 - accuracy: 2.5210e-04 - val_loss: 18.4944 - val_accuracy: 4.4294e-04\n",
      "Epoch 206/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.3152 - accuracy: 2.2761e-04 - val_loss: 17.5026 - val_accuracy: 3.6911e-05\n",
      "Epoch 207/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 26.2869 - accuracy: 2.2041e-04 - val_loss: 17.8862 - val_accuracy: 3.6911e-04\n",
      "Epoch 208/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 26.2878 - accuracy: 2.2185e-04 - val_loss: 17.8008 - val_accuracy: 4.4294e-04\n",
      "Epoch 209/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 26.2726 - accuracy: 2.0456e-04 - val_loss: 16.4893 - val_accuracy: 3.6911e-05\n",
      "Epoch 210/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 26.2903 - accuracy: 2.2473e-04 - val_loss: 18.4390 - val_accuracy: 4.0602e-04\n",
      "Epoch 211/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 26.2737 - accuracy: 2.1465e-04 - val_loss: 16.7997 - val_accuracy: 4.0602e-04\n",
      "Epoch 212/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 26.2637 - accuracy: 2.1176e-04 - val_loss: 16.0486 - val_accuracy: 4.0602e-04\n",
      "Epoch 213/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.2528 - accuracy: 2.2905e-04 - val_loss: 16.3510 - val_accuracy: 4.0602e-04\n",
      "Epoch 214/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.2417 - accuracy: 2.1609e-04 - val_loss: 18.0799 - val_accuracy: 3.6911e-05\n",
      "Epoch 215/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.2401 - accuracy: 2.2041e-04 - val_loss: 17.6397 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 26.1959 - accuracy: 2.1753e-04 - val_loss: 18.2065 - val_accuracy: 3.6911e-05\n",
      "Epoch 217/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.1969 - accuracy: 2.3049e-04 - val_loss: 19.6565 - val_accuracy: 4.4294e-04\n",
      "Epoch 218/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 26.1833 - accuracy: 2.2473e-04 - val_loss: 17.1477 - val_accuracy: 4.7985e-04\n",
      "Epoch 219/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 26.1402 - accuracy: 2.3193e-04 - val_loss: 16.5241 - val_accuracy: 3.6911e-04\n",
      "Epoch 220/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 26.1756 - accuracy: 2.4346e-04 - val_loss: 18.3821 - val_accuracy: 3.6911e-04\n",
      "Epoch 221/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.1533 - accuracy: 2.5354e-04 - val_loss: 16.9720 - val_accuracy: 3.6911e-04\n",
      "Epoch 222/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 26.1272 - accuracy: 2.4346e-04 - val_loss: 16.7253 - val_accuracy: 3.6911e-04\n",
      "Epoch 223/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 26.1328 - accuracy: 2.4490e-04 - val_loss: 19.3956 - val_accuracy: 3.6911e-04\n",
      "Epoch 224/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 26.1215 - accuracy: 2.4922e-04 - val_loss: 17.0145 - val_accuracy: 3.6911e-04\n",
      "Epoch 225/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 26.1714 - accuracy: 2.4922e-04 - val_loss: 16.5338 - val_accuracy: 3.6911e-04\n",
      "Epoch 226/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.1020 - accuracy: 2.6939e-04 - val_loss: 16.4924 - val_accuracy: 3.6911e-04\n",
      "Epoch 227/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 26.0958 - accuracy: 2.4058e-04 - val_loss: 18.1632 - val_accuracy: 4.0602e-04\n",
      "Epoch 228/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.0927 - accuracy: 2.5354e-04 - val_loss: 18.1215 - val_accuracy: 3.6911e-04\n",
      "Epoch 229/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 26.0898 - accuracy: 2.6362e-04 - val_loss: 15.6643 - val_accuracy: 3.6911e-04\n",
      "Epoch 230/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 26.0826 - accuracy: 2.5498e-04 - val_loss: 16.8936 - val_accuracy: 3.6911e-04\n",
      "Epoch 231/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 26.0929 - accuracy: 2.4922e-04 - val_loss: 19.9528 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 26.0810 - accuracy: 2.5066e-04 - val_loss: 16.7064 - val_accuracy: 3.6911e-04\n",
      "Epoch 233/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 26.0362 - accuracy: 2.4202e-04 - val_loss: 16.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "10847/10847 [==============================] - 10s 883us/step - loss: 26.0807 - accuracy: 2.2761e-04 - val_loss: 15.6564 - val_accuracy: 3.6911e-04\n",
      "Epoch 235/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 26.0645 - accuracy: 2.3481e-04 - val_loss: 18.0870 - val_accuracy: 3.6911e-04\n",
      "Epoch 236/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 26.0081 - accuracy: 2.3337e-04 - val_loss: 17.3640 - val_accuracy: 4.0602e-04\n",
      "Epoch 237/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 26.0469 - accuracy: 2.5498e-04 - val_loss: 18.8899 - val_accuracy: 3.6911e-04\n",
      "Epoch 238/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.0167 - accuracy: 2.4778e-04 - val_loss: 16.8099 - val_accuracy: 3.6911e-04\n",
      "Epoch 239/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 26.0246 - accuracy: 2.3481e-04 - val_loss: 17.4315 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 26.0009 - accuracy: 2.4778e-04 - val_loss: 17.9959 - val_accuracy: 4.0602e-04\n",
      "Epoch 241/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 26.0113 - accuracy: 2.4778e-04 - val_loss: 16.6154 - val_accuracy: 3.6911e-04\n",
      "Epoch 242/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.9998 - accuracy: 2.2041e-04 - val_loss: 17.0245 - val_accuracy: 3.6911e-04\n",
      "Epoch 243/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.9852 - accuracy: 2.3625e-04 - val_loss: 16.3154 - val_accuracy: 4.0602e-04\n",
      "Epoch 244/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.9828 - accuracy: 2.4778e-04 - val_loss: 19.1360 - val_accuracy: 4.4294e-04\n",
      "Epoch 245/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.9916 - accuracy: 2.1753e-04 - val_loss: 18.8159 - val_accuracy: 3.6911e-04\n",
      "Epoch 246/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.9977 - accuracy: 2.3193e-04 - val_loss: 16.5924 - val_accuracy: 3.6911e-04\n",
      "Epoch 247/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.9935 - accuracy: 2.3481e-04 - val_loss: 15.3455 - val_accuracy: 3.6911e-04\n",
      "Epoch 248/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 26.0029 - accuracy: 2.4058e-04 - val_loss: 17.2170 - val_accuracy: 3.6911e-04\n",
      "Epoch 249/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.9987 - accuracy: 2.5066e-04 - val_loss: 21.2825 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.9424 - accuracy: 2.3481e-04 - val_loss: 16.1902 - val_accuracy: 3.6911e-04\n",
      "Epoch 251/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.9859 - accuracy: 2.3049e-04 - val_loss: 16.2790 - val_accuracy: 3.6911e-04\n",
      "Epoch 252/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 26.0259 - accuracy: 2.3625e-04 - val_loss: 16.8396 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.9817 - accuracy: 2.2329e-04 - val_loss: 17.9121 - val_accuracy: 3.6911e-04\n",
      "Epoch 254/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.9878 - accuracy: 2.2761e-04 - val_loss: 16.8765 - val_accuracy: 3.6911e-04\n",
      "Epoch 255/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.9732 - accuracy: 2.3337e-04 - val_loss: 15.6968 - val_accuracy: 3.6911e-04\n",
      "Epoch 256/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 25.9874 - accuracy: 2.2041e-04 - val_loss: 17.1462 - val_accuracy: 3.6911e-04\n",
      "Epoch 257/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.9656 - accuracy: 2.2041e-04 - val_loss: 15.6621 - val_accuracy: 3.6911e-04\n",
      "Epoch 258/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.9238 - accuracy: 2.1465e-04 - val_loss: 15.8918 - val_accuracy: 3.6911e-04\n",
      "Epoch 259/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.9495 - accuracy: 2.2329e-04 - val_loss: 16.2858 - val_accuracy: 3.6911e-04\n",
      "Epoch 260/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.9681 - accuracy: 2.3193e-04 - val_loss: 15.7508 - val_accuracy: 3.6911e-04\n",
      "Epoch 261/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 26.0007 - accuracy: 2.2185e-04 - val_loss: 16.9349 - val_accuracy: 3.6911e-04\n",
      "Epoch 262/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.9604 - accuracy: 2.2041e-04 - val_loss: 15.2933 - val_accuracy: 3.6911e-04\n",
      "Epoch 263/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.9839 - accuracy: 2.4634e-04 - val_loss: 16.6860 - val_accuracy: 3.6911e-04\n",
      "Epoch 264/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.9797 - accuracy: 2.1465e-04 - val_loss: 15.4556 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.9807 - accuracy: 2.2473e-04 - val_loss: 16.4617 - val_accuracy: 3.6911e-04\n",
      "Epoch 266/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.9793 - accuracy: 2.4058e-04 - val_loss: 17.7030 - val_accuracy: 0.0012\n",
      "Epoch 267/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.9832 - accuracy: 2.2185e-04 - val_loss: 16.3935 - val_accuracy: 3.6911e-04\n",
      "Epoch 268/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.9761 - accuracy: 2.2617e-04 - val_loss: 16.9536 - val_accuracy: 3.6911e-04\n",
      "Epoch 269/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.9125 - accuracy: 2.2761e-04 - val_loss: 16.5754 - val_accuracy: 3.6911e-04\n",
      "Epoch 270/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.9306 - accuracy: 2.1609e-04 - val_loss: 16.7375 - val_accuracy: 3.6911e-04\n",
      "Epoch 271/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.9325 - accuracy: 2.2617e-04 - val_loss: 19.6928 - val_accuracy: 4.0602e-04\n",
      "Epoch 272/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.9383 - accuracy: 2.1609e-04 - val_loss: 15.2195 - val_accuracy: 3.6911e-04\n",
      "Epoch 273/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.9564 - accuracy: 2.1609e-04 - val_loss: 16.4394 - val_accuracy: 4.4294e-04\n",
      "Epoch 274/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.9631 - accuracy: 2.2329e-04 - val_loss: 28.6237 - val_accuracy: 3.6911e-04\n",
      "Epoch 275/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.9556 - accuracy: 2.5930e-04 - val_loss: 19.6095 - val_accuracy: 0.0012\n",
      "Epoch 276/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.9233 - accuracy: 2.3049e-04 - val_loss: 17.0233 - val_accuracy: 3.6911e-04\n",
      "Epoch 277/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.9069 - accuracy: 2.4058e-04 - val_loss: 17.2443 - val_accuracy: 3.6911e-04\n",
      "Epoch 278/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.8942 - accuracy: 2.2185e-04 - val_loss: 15.9841 - val_accuracy: 3.6911e-04\n",
      "Epoch 279/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.8599 - accuracy: 2.1753e-04 - val_loss: 18.0373 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.8893 - accuracy: 2.4634e-04 - val_loss: 18.7535 - val_accuracy: 3.6911e-04\n",
      "Epoch 281/1000\n",
      "10847/10847 [==============================] - 10s 965us/step - loss: 25.8550 - accuracy: 2.3625e-04 - val_loss: 16.4836 - val_accuracy: 3.6911e-04\n",
      "Epoch 282/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.8617 - accuracy: 2.1753e-04 - val_loss: 16.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.8347 - accuracy: 2.4202e-04 - val_loss: 17.5448 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.8386 - accuracy: 2.3769e-04 - val_loss: 16.0563 - val_accuracy: 4.0602e-04\n",
      "Epoch 285/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.8711 - accuracy: 2.2761e-04 - val_loss: 15.6437 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "10847/10847 [==============================] - 10s 906us/step - loss: 25.8561 - accuracy: 2.4490e-04 - val_loss: 17.2214 - val_accuracy: 3.6911e-04\n",
      "Epoch 287/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 25.8811 - accuracy: 2.3769e-04 - val_loss: 17.3802 - val_accuracy: 4.0602e-04\n",
      "Epoch 288/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.8418 - accuracy: 2.3337e-04 - val_loss: 16.4100 - val_accuracy: 3.6911e-04\n",
      "Epoch 289/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.8466 - accuracy: 2.3049e-04 - val_loss: 14.4859 - val_accuracy: 3.6911e-04\n",
      "Epoch 290/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.8773 - accuracy: 2.5066e-04 - val_loss: 16.3069 - val_accuracy: 3.6911e-04\n",
      "Epoch 291/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.8668 - accuracy: 2.5066e-04 - val_loss: 16.3977 - val_accuracy: 3.6911e-04\n",
      "Epoch 292/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.8715 - accuracy: 2.6507e-04 - val_loss: 18.1455 - val_accuracy: 3.6911e-04\n",
      "Epoch 293/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.8755 - accuracy: 2.5354e-04 - val_loss: 16.8524 - val_accuracy: 3.6911e-04\n",
      "Epoch 294/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.8715 - accuracy: 2.5786e-04 - val_loss: 16.1533 - val_accuracy: 3.6911e-04\n",
      "Epoch 295/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.8267 - accuracy: 2.4634e-04 - val_loss: 14.6634 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.8414 - accuracy: 2.3625e-04 - val_loss: 18.4328 - val_accuracy: 3.6911e-04\n",
      "Epoch 297/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.8377 - accuracy: 2.2473e-04 - val_loss: 15.0219 - val_accuracy: 3.6911e-04\n",
      "Epoch 298/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.8210 - accuracy: 2.3914e-04 - val_loss: 14.6382 - val_accuracy: 3.6911e-04\n",
      "Epoch 299/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.8449 - accuracy: 2.4634e-04 - val_loss: 17.5567 - val_accuracy: 3.6911e-04\n",
      "Epoch 300/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.8363 - accuracy: 2.5066e-04 - val_loss: 14.9170 - val_accuracy: 3.6911e-04\n",
      "Epoch 301/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.8124 - accuracy: 2.5498e-04 - val_loss: 18.1075 - val_accuracy: 3.6911e-04\n",
      "Epoch 302/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.8165 - accuracy: 2.4778e-04 - val_loss: 14.8232 - val_accuracy: 3.6911e-04\n",
      "Epoch 303/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.8255 - accuracy: 2.2761e-04 - val_loss: 16.5289 - val_accuracy: 3.6911e-04\n",
      "Epoch 304/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.8424 - accuracy: 2.2761e-04 - val_loss: 16.9430 - val_accuracy: 3.6911e-04\n",
      "Epoch 305/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.8275 - accuracy: 2.3193e-04 - val_loss: 17.2363 - val_accuracy: 3.6911e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.7938 - accuracy: 2.4058e-04 - val_loss: 15.8302 - val_accuracy: 3.6911e-04\n",
      "Epoch 307/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.7920 - accuracy: 2.4202e-04 - val_loss: 14.8468 - val_accuracy: 3.6911e-04\n",
      "Epoch 308/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7860 - accuracy: 2.3914e-04 - val_loss: 16.9139 - val_accuracy: 3.6911e-04\n",
      "Epoch 309/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.7913 - accuracy: 2.3914e-04 - val_loss: 16.5037 - val_accuracy: 4.0602e-04\n",
      "Epoch 310/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.8023 - accuracy: 2.4058e-04 - val_loss: 16.7346 - val_accuracy: 3.6911e-04\n",
      "Epoch 311/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.8052 - accuracy: 2.6651e-04 - val_loss: 16.5597 - val_accuracy: 4.0602e-04\n",
      "Epoch 312/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7873 - accuracy: 2.3193e-04 - val_loss: 15.9800 - val_accuracy: 3.6911e-04\n",
      "Epoch 313/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.8027 - accuracy: 2.1465e-04 - val_loss: 14.9587 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7682 - accuracy: 2.5642e-04 - val_loss: 14.8946 - val_accuracy: 3.6911e-04\n",
      "Epoch 315/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7734 - accuracy: 2.2761e-04 - val_loss: 16.8862 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "10847/10847 [==============================] - 9s 852us/step - loss: 25.7835 - accuracy: 2.3049e-04 - val_loss: 18.4533 - val_accuracy: 3.6911e-04\n",
      "Epoch 317/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7959 - accuracy: 2.4778e-04 - val_loss: 16.7778 - val_accuracy: 3.6911e-04\n",
      "Epoch 318/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.8005 - accuracy: 2.4490e-04 - val_loss: 15.0324 - val_accuracy: 3.6911e-04\n",
      "Epoch 319/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7903 - accuracy: 2.2761e-04 - val_loss: 17.1905 - val_accuracy: 4.4294e-04\n",
      "Epoch 320/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.7669 - accuracy: 2.2905e-04 - val_loss: 15.2585 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7819 - accuracy: 2.5354e-04 - val_loss: 16.0401 - val_accuracy: 3.6911e-04\n",
      "Epoch 322/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7552 - accuracy: 2.6218e-04 - val_loss: 15.6544 - val_accuracy: 3.6911e-04\n",
      "Epoch 323/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7778 - accuracy: 2.5066e-04 - val_loss: 17.9776 - val_accuracy: 3.6911e-04\n",
      "Epoch 324/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7637 - accuracy: 2.2617e-04 - val_loss: 17.5557 - val_accuracy: 3.6911e-04\n",
      "Epoch 325/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7551 - accuracy: 2.3625e-04 - val_loss: 16.8234 - val_accuracy: 3.6911e-04\n",
      "Epoch 326/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7480 - accuracy: 2.4346e-04 - val_loss: 15.1036 - val_accuracy: 3.6911e-04\n",
      "Epoch 327/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7705 - accuracy: 2.2905e-04 - val_loss: 18.0287 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7739 - accuracy: 2.3337e-04 - val_loss: 16.2359 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7336 - accuracy: 2.3625e-04 - val_loss: 15.8835 - val_accuracy: 3.6911e-04\n",
      "Epoch 330/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7806 - accuracy: 2.4490e-04 - val_loss: 17.1787 - val_accuracy: 4.0602e-04\n",
      "Epoch 331/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7495 - accuracy: 2.3914e-04 - val_loss: 15.4785 - val_accuracy: 3.6911e-04\n",
      "Epoch 332/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7310 - accuracy: 2.2905e-04 - val_loss: 17.1510 - val_accuracy: 3.6911e-04\n",
      "Epoch 333/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 25.7403 - accuracy: 2.4634e-04 - val_loss: 15.0270 - val_accuracy: 3.6911e-04\n",
      "Epoch 334/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7749 - accuracy: 2.6795e-04 - val_loss: 16.4365 - val_accuracy: 4.0602e-04\n",
      "Epoch 335/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 25.7581 - accuracy: 2.2761e-04 - val_loss: 20.8565 - val_accuracy: 0.0012\n",
      "Epoch 336/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7490 - accuracy: 2.4058e-04 - val_loss: 16.6866 - val_accuracy: 4.0602e-04\n",
      "Epoch 337/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 25.7302 - accuracy: 2.3049e-04 - val_loss: 14.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7243 - accuracy: 2.5498e-04 - val_loss: 16.8426 - val_accuracy: 3.6911e-04\n",
      "Epoch 339/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7507 - accuracy: 2.5066e-04 - val_loss: 15.3845 - val_accuracy: 3.6911e-04\n",
      "Epoch 340/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7253 - accuracy: 2.3193e-04 - val_loss: 15.1961 - val_accuracy: 3.6911e-04\n",
      "Epoch 341/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.7054 - accuracy: 2.5354e-04 - val_loss: 16.5972 - val_accuracy: 3.6911e-04\n",
      "Epoch 342/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7134 - accuracy: 2.4202e-04 - val_loss: 17.9471 - val_accuracy: 3.6911e-04\n",
      "Epoch 343/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7369 - accuracy: 2.4922e-04 - val_loss: 17.3128 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7067 - accuracy: 2.5354e-04 - val_loss: 15.7997 - val_accuracy: 4.0602e-04\n",
      "Epoch 345/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7278 - accuracy: 2.2617e-04 - val_loss: 18.1838 - val_accuracy: 3.6911e-04\n",
      "Epoch 346/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.7487 - accuracy: 2.4490e-04 - val_loss: 17.3987 - val_accuracy: 4.4294e-04\n",
      "Epoch 347/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7259 - accuracy: 2.2761e-04 - val_loss: 15.0059 - val_accuracy: 3.6911e-04\n",
      "Epoch 348/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7496 - accuracy: 2.1897e-04 - val_loss: 15.8098 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7679 - accuracy: 2.3914e-04 - val_loss: 17.0744 - val_accuracy: 3.6911e-04\n",
      "Epoch 350/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.7568 - accuracy: 2.3481e-04 - val_loss: 16.4695 - val_accuracy: 3.6911e-04\n",
      "Epoch 351/1000\n",
      "10847/10847 [==============================] - 9s 852us/step - loss: 25.7604 - accuracy: 2.5642e-04 - val_loss: 16.9904 - val_accuracy: 3.6911e-04\n",
      "Epoch 352/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7462 - accuracy: 2.2905e-04 - val_loss: 19.1461 - val_accuracy: 4.0602e-04\n",
      "Epoch 353/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7114 - accuracy: 2.2905e-04 - val_loss: 15.7504 - val_accuracy: 3.6911e-04\n",
      "Epoch 354/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7254 - accuracy: 2.3914e-04 - val_loss: 15.9644 - val_accuracy: 3.6911e-04\n",
      "Epoch 355/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7760 - accuracy: 2.2761e-04 - val_loss: 19.2781 - val_accuracy: 3.6911e-04\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7166 - accuracy: 2.3481e-04 - val_loss: 17.5603 - val_accuracy: 3.6911e-04\n",
      "Epoch 357/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7126 - accuracy: 2.5066e-04 - val_loss: 14.5403 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7035 - accuracy: 2.4634e-04 - val_loss: 16.6414 - val_accuracy: 4.4294e-04\n",
      "Epoch 359/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7626 - accuracy: 2.3914e-04 - val_loss: 16.8485 - val_accuracy: 3.6911e-04\n",
      "Epoch 360/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7440 - accuracy: 2.3769e-04 - val_loss: 15.8510 - val_accuracy: 3.6911e-04\n",
      "Epoch 361/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7564 - accuracy: 2.5498e-04 - val_loss: 14.7967 - val_accuracy: 3.6911e-04\n",
      "Epoch 362/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7154 - accuracy: 2.2473e-04 - val_loss: 17.9108 - val_accuracy: 0.0012\n",
      "Epoch 363/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7669 - accuracy: 2.3481e-04 - val_loss: 16.1323 - val_accuracy: 3.6911e-04\n",
      "Epoch 364/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7161 - accuracy: 2.3914e-04 - val_loss: 16.2744 - val_accuracy: 3.6911e-04\n",
      "Epoch 365/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7596 - accuracy: 2.4490e-04 - val_loss: 15.8350 - val_accuracy: 3.6911e-04\n",
      "Epoch 366/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7253 - accuracy: 2.3337e-04 - val_loss: 15.8406 - val_accuracy: 3.6911e-04\n",
      "Epoch 367/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7325 - accuracy: 2.3337e-04 - val_loss: 16.3587 - val_accuracy: 3.6911e-04\n",
      "Epoch 368/1000\n",
      "10847/10847 [==============================] - 9s 852us/step - loss: 25.7614 - accuracy: 2.1753e-04 - val_loss: 14.9078 - val_accuracy: 3.6911e-04\n",
      "Epoch 369/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.8012 - accuracy: 2.3481e-04 - val_loss: 15.6153 - val_accuracy: 3.6911e-04\n",
      "Epoch 370/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7629 - accuracy: 2.3049e-04 - val_loss: 19.8785 - val_accuracy: 3.6911e-04\n",
      "Epoch 371/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7745 - accuracy: 2.4922e-04 - val_loss: 17.1207 - val_accuracy: 3.6911e-04\n",
      "Epoch 372/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7622 - accuracy: 2.2329e-04 - val_loss: 16.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7492 - accuracy: 2.3769e-04 - val_loss: 16.2947 - val_accuracy: 3.6911e-04\n",
      "Epoch 374/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.7655 - accuracy: 2.4490e-04 - val_loss: 15.2650 - val_accuracy: 3.6911e-04\n",
      "Epoch 375/1000\n",
      "10847/10847 [==============================] - 10s 921us/step - loss: 25.7683 - accuracy: 2.4058e-04 - val_loss: 18.1242 - val_accuracy: 3.6911e-04\n",
      "Epoch 376/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 25.7722 - accuracy: 2.3625e-04 - val_loss: 16.6081 - val_accuracy: 3.6911e-04\n",
      "Epoch 377/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7040 - accuracy: 2.3193e-04 - val_loss: 18.6636 - val_accuracy: 3.6911e-04\n",
      "Epoch 378/1000\n",
      "10847/10847 [==============================] - 10s 879us/step - loss: 25.7274 - accuracy: 2.2473e-04 - val_loss: 14.3337 - val_accuracy: 3.6911e-04\n",
      "Epoch 379/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7201 - accuracy: 2.3769e-04 - val_loss: 17.4619 - val_accuracy: 4.0602e-04\n",
      "Epoch 380/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7655 - accuracy: 2.4346e-04 - val_loss: 15.9868 - val_accuracy: 3.6911e-04\n",
      "Epoch 381/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7726 - accuracy: 2.3049e-04 - val_loss: 18.6225 - val_accuracy: 4.0602e-04\n",
      "Epoch 382/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7797 - accuracy: 2.3625e-04 - val_loss: 17.2784 - val_accuracy: 3.6911e-04\n",
      "Epoch 383/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7568 - accuracy: 2.3625e-04 - val_loss: 15.9964 - val_accuracy: 3.6911e-04\n",
      "Epoch 384/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7577 - accuracy: 2.3193e-04 - val_loss: 14.8634 - val_accuracy: 3.6911e-04\n",
      "Epoch 385/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7158 - accuracy: 2.2473e-04 - val_loss: 16.7742 - val_accuracy: 3.6911e-04\n",
      "Epoch 386/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7439 - accuracy: 2.3625e-04 - val_loss: 15.0195 - val_accuracy: 3.6911e-04\n",
      "Epoch 387/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7417 - accuracy: 2.2761e-04 - val_loss: 16.5494 - val_accuracy: 3.6911e-04\n",
      "Epoch 388/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7241 - accuracy: 2.3914e-04 - val_loss: 15.4507 - val_accuracy: 3.6911e-04\n",
      "Epoch 389/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.7400 - accuracy: 2.3337e-04 - val_loss: 14.7990 - val_accuracy: 3.6911e-04\n",
      "Epoch 390/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7500 - accuracy: 2.3481e-04 - val_loss: 16.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.7248 - accuracy: 2.3337e-04 - val_loss: 16.5133 - val_accuracy: 3.6911e-04\n",
      "Epoch 392/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7031 - accuracy: 2.3337e-04 - val_loss: 17.0674 - val_accuracy: 4.0602e-04\n",
      "Epoch 393/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7422 - accuracy: 2.4202e-04 - val_loss: 14.3224 - val_accuracy: 3.6911e-04\n",
      "Epoch 394/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7171 - accuracy: 2.3193e-04 - val_loss: 15.7034 - val_accuracy: 3.6911e-04\n",
      "Epoch 395/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.6910 - accuracy: 2.3914e-04 - val_loss: 18.8859 - val_accuracy: 0.0012\n",
      "Epoch 396/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7188 - accuracy: 2.2185e-04 - val_loss: 16.9741 - val_accuracy: 3.6911e-04\n",
      "Epoch 397/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7443 - accuracy: 2.2041e-04 - val_loss: 17.8002 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7354 - accuracy: 2.3481e-04 - val_loss: 16.0927 - val_accuracy: 3.6911e-04\n",
      "Epoch 399/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7119 - accuracy: 2.2905e-04 - val_loss: 14.6480 - val_accuracy: 3.6911e-04\n",
      "Epoch 400/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7421 - accuracy: 2.3337e-04 - val_loss: 15.8330 - val_accuracy: 3.6911e-04\n",
      "Epoch 401/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7520 - accuracy: 2.2473e-04 - val_loss: 16.2111 - val_accuracy: 4.0602e-04\n",
      "Epoch 402/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7566 - accuracy: 2.2185e-04 - val_loss: 15.9206 - val_accuracy: 3.6911e-04\n",
      "Epoch 403/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.8153 - accuracy: 2.4202e-04 - val_loss: 16.4965 - val_accuracy: 4.0602e-04\n",
      "Epoch 404/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 25.7720 - accuracy: 2.5642e-04 - val_loss: 16.4843 - val_accuracy: 3.3220e-04\n",
      "Epoch 405/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7663 - accuracy: 2.3337e-04 - val_loss: 14.8548 - val_accuracy: 3.6911e-04\n",
      "Epoch 406/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7132 - accuracy: 2.3625e-04 - val_loss: 15.6594 - val_accuracy: 3.6911e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7058 - accuracy: 2.3193e-04 - val_loss: 15.4434 - val_accuracy: 3.6911e-04\n",
      "Epoch 408/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7155 - accuracy: 2.3625e-04 - val_loss: 17.0959 - val_accuracy: 3.6911e-04\n",
      "Epoch 409/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7214 - accuracy: 2.3193e-04 - val_loss: 14.5730 - val_accuracy: 3.6911e-04\n",
      "Epoch 410/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7227 - accuracy: 2.4202e-04 - val_loss: 17.3822 - val_accuracy: 3.6911e-04\n",
      "Epoch 411/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7096 - accuracy: 2.3193e-04 - val_loss: 15.3510 - val_accuracy: 3.6911e-04\n",
      "Epoch 412/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7106 - accuracy: 2.2329e-04 - val_loss: 18.7838 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7204 - accuracy: 2.2761e-04 - val_loss: 13.5336 - val_accuracy: 3.6911e-04\n",
      "Epoch 414/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7438 - accuracy: 2.4346e-04 - val_loss: 15.1833 - val_accuracy: 3.6911e-04\n",
      "Epoch 415/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7185 - accuracy: 2.3914e-04 - val_loss: 15.7589 - val_accuracy: 3.6911e-04\n",
      "Epoch 416/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7684 - accuracy: 2.2761e-04 - val_loss: 17.5624 - val_accuracy: 4.4294e-04\n",
      "Epoch 417/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.6842 - accuracy: 2.3914e-04 - val_loss: 25.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "10847/10847 [==============================] - 9s 850us/step - loss: 25.7299 - accuracy: 2.3049e-04 - val_loss: 16.7001 - val_accuracy: 4.0602e-04\n",
      "Epoch 419/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7096 - accuracy: 2.2329e-04 - val_loss: 14.3690 - val_accuracy: 3.6911e-04\n",
      "Epoch 420/1000\n",
      "10847/10847 [==============================] - 9s 852us/step - loss: 25.6947 - accuracy: 2.2617e-04 - val_loss: 15.7068 - val_accuracy: 3.6911e-04\n",
      "Epoch 421/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7153 - accuracy: 2.2761e-04 - val_loss: 15.8155 - val_accuracy: 3.6911e-04\n",
      "Epoch 422/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7385 - accuracy: 2.1465e-04 - val_loss: 17.4621 - val_accuracy: 4.4294e-04\n",
      "Epoch 423/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.7322 - accuracy: 2.4346e-04 - val_loss: 16.7109 - val_accuracy: 3.6911e-04\n",
      "Epoch 424/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7298 - accuracy: 2.3914e-04 - val_loss: 15.4743 - val_accuracy: 3.6911e-04\n",
      "Epoch 425/1000\n",
      "10847/10847 [==============================] - 9s 856us/step - loss: 25.7528 - accuracy: 2.3625e-04 - val_loss: 14.4971 - val_accuracy: 3.6911e-04\n",
      "Epoch 426/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7676 - accuracy: 2.1897e-04 - val_loss: 15.1892 - val_accuracy: 4.0602e-04\n",
      "Epoch 427/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7510 - accuracy: 2.1320e-04 - val_loss: 15.3660 - val_accuracy: 3.6911e-04\n",
      "Epoch 428/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7203 - accuracy: 2.3193e-04 - val_loss: 16.9559 - val_accuracy: 3.6911e-04\n",
      "Epoch 429/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7717 - accuracy: 2.3481e-04 - val_loss: 16.7862 - val_accuracy: 3.6911e-04\n",
      "Epoch 430/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7356 - accuracy: 2.3049e-04 - val_loss: 17.3722 - val_accuracy: 3.6911e-04\n",
      "Epoch 431/1000\n",
      "10847/10847 [==============================] - 9s 851us/step - loss: 25.7636 - accuracy: 2.4202e-04 - val_loss: 16.9972 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.7558 - accuracy: 2.4346e-04 - val_loss: 16.3421 - val_accuracy: 3.6911e-04\n",
      "Epoch 433/1000\n",
      "10847/10847 [==============================] - 9s 854us/step - loss: 25.7146 - accuracy: 2.2185e-04 - val_loss: 16.1621 - val_accuracy: 3.6911e-04\n",
      "Epoch 434/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7285 - accuracy: 2.2473e-04 - val_loss: 16.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.6956 - accuracy: 2.2617e-04 - val_loss: 16.0891 - val_accuracy: 3.6911e-04\n",
      "Epoch 436/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 25.7360 - accuracy: 2.1897e-04 - val_loss: 14.7777 - val_accuracy: 3.6911e-04\n",
      "Epoch 437/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.7314 - accuracy: 2.1465e-04 - val_loss: 17.4098 - val_accuracy: 3.6911e-04\n",
      "Epoch 438/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7417 - accuracy: 2.3769e-04 - val_loss: 16.4003 - val_accuracy: 3.6911e-04\n",
      "Epoch 439/1000\n",
      "10847/10847 [==============================] - 9s 857us/step - loss: 25.6958 - accuracy: 2.3625e-04 - val_loss: 14.3462 - val_accuracy: 3.6911e-04\n",
      "Epoch 440/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.6901 - accuracy: 2.2905e-04 - val_loss: 14.5698 - val_accuracy: 3.6911e-04\n",
      "Epoch 441/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7235 - accuracy: 2.3481e-04 - val_loss: 15.2234 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 25.7206 - accuracy: 2.3625e-04 - val_loss: 17.6487 - val_accuracy: 3.6911e-04\n",
      "Epoch 443/1000\n",
      "10847/10847 [==============================] - 9s 855us/step - loss: 25.7113 - accuracy: 2.3049e-04 - val_loss: 16.0071 - val_accuracy: 3.6911e-04\n",
      "Epoch 444/1000\n",
      "10847/10847 [==============================] - 9s 853us/step - loss: 25.7320 - accuracy: 2.2041e-04 - val_loss: 16.8134 - val_accuracy: 3.6911e-04\n",
      "Epoch 445/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7316 - accuracy: 2.3769e-04 - val_loss: 13.8248 - val_accuracy: 3.6911e-04\n",
      "Epoch 446/1000\n",
      "10847/10847 [==============================] - 9s 862us/step - loss: 25.7104 - accuracy: 2.3625e-04 - val_loss: 14.4710 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "10847/10847 [==============================] - 10s 932us/step - loss: 25.6920 - accuracy: 2.2473e-04 - val_loss: 15.4297 - val_accuracy: 3.6911e-04\n",
      "Epoch 448/1000\n",
      "10847/10847 [==============================] - 10s 887us/step - loss: 25.7416 - accuracy: 2.3049e-04 - val_loss: 17.4780 - val_accuracy: 3.6911e-04\n",
      "Epoch 449/1000\n",
      "10847/10847 [==============================] - 10s 879us/step - loss: 25.7463 - accuracy: 2.2617e-04 - val_loss: 14.8249 - val_accuracy: 3.6911e-04\n",
      "Epoch 450/1000\n",
      "10847/10847 [==============================] - 9s 874us/step - loss: 25.7034 - accuracy: 2.3481e-04 - val_loss: 16.6734 - val_accuracy: 4.0602e-04\n",
      "Epoch 451/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 25.7691 - accuracy: 2.1753e-04 - val_loss: 16.5793 - val_accuracy: 3.6911e-04\n",
      "Epoch 452/1000\n",
      "10847/10847 [==============================] - 9s 874us/step - loss: 25.7360 - accuracy: 2.1176e-04 - val_loss: 14.8389 - val_accuracy: 3.6911e-04\n",
      "Epoch 453/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 25.7488 - accuracy: 2.3337e-04 - val_loss: 15.1482 - val_accuracy: 3.6911e-04\n",
      "Epoch 454/1000\n",
      "10847/10847 [==============================] - 10s 886us/step - loss: 25.7299 - accuracy: 2.2185e-04 - val_loss: 17.6679 - val_accuracy: 3.6911e-04\n",
      "Epoch 455/1000\n",
      "10847/10847 [==============================] - 10s 887us/step - loss: 25.7297 - accuracy: 2.0888e-04 - val_loss: 15.4673 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7352 - accuracy: 2.2617e-04 - val_loss: 15.7876 - val_accuracy: 3.6911e-04\n",
      "Epoch 457/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 9s 874us/step - loss: 25.7637 - accuracy: 2.2905e-04 - val_loss: 15.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "10847/10847 [==============================] - 10s 878us/step - loss: 25.7735 - accuracy: 2.2617e-04 - val_loss: 15.5800 - val_accuracy: 3.6911e-04\n",
      "Epoch 459/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7150 - accuracy: 2.2617e-04 - val_loss: 17.2789 - val_accuracy: 4.0602e-04\n",
      "Epoch 460/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7378 - accuracy: 2.1465e-04 - val_loss: 15.5458 - val_accuracy: 3.6911e-04\n",
      "Epoch 461/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7489 - accuracy: 2.4058e-04 - val_loss: 17.4242 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7571 - accuracy: 2.2617e-04 - val_loss: 14.2391 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.7399 - accuracy: 2.3193e-04 - val_loss: 13.9524 - val_accuracy: 3.6911e-04\n",
      "Epoch 464/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7553 - accuracy: 2.3337e-04 - val_loss: 15.3770 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 25.8028 - accuracy: 2.2185e-04 - val_loss: 14.8434 - val_accuracy: 3.6911e-04\n",
      "Epoch 466/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 25.7912 - accuracy: 2.0600e-04 - val_loss: 14.4314 - val_accuracy: 4.0602e-04\n",
      "Epoch 467/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7807 - accuracy: 2.1320e-04 - val_loss: 16.9604 - val_accuracy: 3.6911e-04\n",
      "Epoch 468/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7087 - accuracy: 2.2473e-04 - val_loss: 15.4689 - val_accuracy: 3.6911e-04\n",
      "Epoch 469/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7152 - accuracy: 2.2905e-04 - val_loss: 17.0577 - val_accuracy: 3.6911e-04\n",
      "Epoch 470/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.7113 - accuracy: 2.4634e-04 - val_loss: 14.6897 - val_accuracy: 3.6911e-04\n",
      "Epoch 471/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 25.7271 - accuracy: 2.1465e-04 - val_loss: 16.4059 - val_accuracy: 3.6911e-04\n",
      "Epoch 472/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.7226 - accuracy: 2.2329e-04 - val_loss: 16.9005 - val_accuracy: 3.6911e-04\n",
      "Epoch 473/1000\n",
      "10847/10847 [==============================] - 9s 860us/step - loss: 25.7242 - accuracy: 2.3914e-04 - val_loss: 16.8029 - val_accuracy: 3.6911e-04\n",
      "Epoch 474/1000\n",
      "10847/10847 [==============================] - 9s 873us/step - loss: 25.7434 - accuracy: 2.2185e-04 - val_loss: 17.1403 - val_accuracy: 3.6911e-04\n",
      "Epoch 475/1000\n",
      "10847/10847 [==============================] - 9s 864us/step - loss: 25.7266 - accuracy: 2.2905e-04 - val_loss: 14.2315 - val_accuracy: 3.6911e-04\n",
      "Epoch 476/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7009 - accuracy: 2.3481e-04 - val_loss: 15.4028 - val_accuracy: 3.6911e-04\n",
      "Epoch 477/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7174 - accuracy: 2.0888e-04 - val_loss: 16.0567 - val_accuracy: 3.6911e-04\n",
      "Epoch 478/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.7003 - accuracy: 2.2761e-04 - val_loss: 16.8778 - val_accuracy: 3.6911e-04\n",
      "Epoch 479/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7223 - accuracy: 2.2473e-04 - val_loss: 15.9022 - val_accuracy: 3.6911e-04\n",
      "Epoch 480/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.6871 - accuracy: 2.1753e-04 - val_loss: 16.2109 - val_accuracy: 3.6911e-04\n",
      "Epoch 481/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7539 - accuracy: 2.1897e-04 - val_loss: 14.9252 - val_accuracy: 3.6911e-04\n",
      "Epoch 482/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7139 - accuracy: 2.1465e-04 - val_loss: 16.9304 - val_accuracy: 3.6911e-04\n",
      "Epoch 483/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.7414 - accuracy: 2.3769e-04 - val_loss: 15.5714 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "10847/10847 [==============================] - 9s 866us/step - loss: 25.7544 - accuracy: 2.3625e-04 - val_loss: 13.8979 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7492 - accuracy: 2.1753e-04 - val_loss: 16.5570 - val_accuracy: 3.6911e-04\n",
      "Epoch 486/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7269 - accuracy: 2.2905e-04 - val_loss: 15.8944 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "10847/10847 [==============================] - 10s 879us/step - loss: 25.7255 - accuracy: 2.3625e-04 - val_loss: 17.2438 - val_accuracy: 3.6911e-04\n",
      "Epoch 488/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7164 - accuracy: 2.2617e-04 - val_loss: 17.4865 - val_accuracy: 3.6911e-04\n",
      "Epoch 489/1000\n",
      "10847/10847 [==============================] - 10s 880us/step - loss: 25.7122 - accuracy: 2.1465e-04 - val_loss: 16.3796 - val_accuracy: 3.6911e-04\n",
      "Epoch 490/1000\n",
      "10847/10847 [==============================] - 10s 886us/step - loss: 25.6945 - accuracy: 2.1897e-04 - val_loss: 19.0637 - val_accuracy: 3.6911e-04\n",
      "Epoch 491/1000\n",
      "10847/10847 [==============================] - 10s 898us/step - loss: 25.7391 - accuracy: 2.2041e-04 - val_loss: 14.8288 - val_accuracy: 3.6911e-04\n",
      "Epoch 492/1000\n",
      "10847/10847 [==============================] - 9s 874us/step - loss: 25.7402 - accuracy: 2.1176e-04 - val_loss: 15.3504 - val_accuracy: 3.6911e-04\n",
      "Epoch 493/1000\n",
      "10847/10847 [==============================] - 10s 893us/step - loss: 25.7012 - accuracy: 2.2617e-04 - val_loss: 16.9436 - val_accuracy: 3.6911e-04\n",
      "Epoch 494/1000\n",
      "10847/10847 [==============================] - 10s 900us/step - loss: 25.6914 - accuracy: 2.5066e-04 - val_loss: 15.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "10847/10847 [==============================] - 10s 913us/step - loss: 25.6972 - accuracy: 2.3049e-04 - val_loss: 15.5615 - val_accuracy: 3.6911e-04\n",
      "Epoch 496/1000\n",
      "10847/10847 [==============================] - 10s 903us/step - loss: 25.7022 - accuracy: 2.3049e-04 - val_loss: 14.3964 - val_accuracy: 3.6911e-04\n",
      "Epoch 497/1000\n",
      "10847/10847 [==============================] - 10s 915us/step - loss: 25.6959 - accuracy: 2.3625e-04 - val_loss: 15.7485 - val_accuracy: 3.6911e-04\n",
      "Epoch 498/1000\n",
      "10847/10847 [==============================] - 10s 938us/step - loss: 25.7506 - accuracy: 2.3769e-04 - val_loss: 15.3220 - val_accuracy: 3.6911e-04\n",
      "Epoch 499/1000\n",
      "10847/10847 [==============================] - 10s 928us/step - loss: 25.6803 - accuracy: 2.2473e-04 - val_loss: 14.7279 - val_accuracy: 3.6911e-04\n",
      "Epoch 500/1000\n",
      "10847/10847 [==============================] - 10s 916us/step - loss: 25.7345 - accuracy: 2.2761e-04 - val_loss: 14.6810 - val_accuracy: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "10847/10847 [==============================] - 10s 931us/step - loss: 25.7381 - accuracy: 2.3914e-04 - val_loss: 17.7379 - val_accuracy: 3.6911e-04\n",
      "Epoch 502/1000\n",
      "10847/10847 [==============================] - 10s 947us/step - loss: 25.6972 - accuracy: 2.2473e-04 - val_loss: 15.4666 - val_accuracy: 3.6911e-04\n",
      "Epoch 503/1000\n",
      "10847/10847 [==============================] - 10s 950us/step - loss: 25.7390 - accuracy: 2.3481e-04 - val_loss: 19.6409 - val_accuracy: 4.0602e-04\n",
      "Epoch 504/1000\n",
      "10847/10847 [==============================] - 10s 961us/step - loss: 25.7016 - accuracy: 2.2905e-04 - val_loss: 16.3792 - val_accuracy: 3.6911e-04\n",
      "Epoch 505/1000\n",
      "10847/10847 [==============================] - 10s 954us/step - loss: 25.6916 - accuracy: 2.1897e-04 - val_loss: 14.2276 - val_accuracy: 3.6911e-04\n",
      "Epoch 506/1000\n",
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7222 - accuracy: 2.2617e-04 - val_loss: 17.0130 - val_accuracy: 3.6911e-04\n",
      "Epoch 507/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7467 - accuracy: 2.1320e-04 - val_loss: 13.5462 - val_accuracy: 3.6911e-04\n",
      "Epoch 508/1000\n",
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7099 - accuracy: 2.3337e-04 - val_loss: 15.1673 - val_accuracy: 3.6911e-04\n",
      "Epoch 509/1000\n",
      "10847/10847 [==============================] - 10s 892us/step - loss: 25.7143 - accuracy: 1.9880e-04 - val_loss: 14.2149 - val_accuracy: 3.6911e-04\n",
      "Epoch 510/1000\n",
      "10847/10847 [==============================] - 11s 977us/step - loss: 25.7223 - accuracy: 2.2041e-04 - val_loss: 13.8987 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "10847/10847 [==============================] - 11s 995us/step - loss: 25.7565 - accuracy: 2.3193e-04 - val_loss: 19.0551 - val_accuracy: 3.6911e-04\n",
      "Epoch 512/1000\n",
      "10847/10847 [==============================] - 11s 981us/step - loss: 25.7722 - accuracy: 2.2905e-04 - val_loss: 14.4532 - val_accuracy: 3.6911e-04\n",
      "Epoch 513/1000\n",
      "10847/10847 [==============================] - 11s 982us/step - loss: 25.7354 - accuracy: 2.2905e-04 - val_loss: 16.5582 - val_accuracy: 3.6911e-04\n",
      "Epoch 514/1000\n",
      "10847/10847 [==============================] - 11s 982us/step - loss: 25.7425 - accuracy: 2.5498e-04 - val_loss: 15.4855 - val_accuracy: 3.6911e-04\n",
      "Epoch 515/1000\n",
      "10847/10847 [==============================] - 11s 986us/step - loss: 25.7389 - accuracy: 2.2041e-04 - val_loss: 15.8594 - val_accuracy: 3.6911e-04\n",
      "Epoch 516/1000\n",
      "10847/10847 [==============================] - 10s 936us/step - loss: 25.7746 - accuracy: 2.1465e-04 - val_loss: 15.3453 - val_accuracy: 3.6911e-04\n",
      "Epoch 517/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7550 - accuracy: 2.2041e-04 - val_loss: 17.4571 - val_accuracy: 3.6911e-04\n",
      "Epoch 518/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7472 - accuracy: 2.3337e-04 - val_loss: 15.4714 - val_accuracy: 3.6911e-04\n",
      "Epoch 519/1000\n",
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7495 - accuracy: 2.1897e-04 - val_loss: 16.5715 - val_accuracy: 3.6911e-04\n",
      "Epoch 520/1000\n",
      "10847/10847 [==============================] - 10s 876us/step - loss: 25.7201 - accuracy: 2.2329e-04 - val_loss: 16.6774 - val_accuracy: 3.6911e-04\n",
      "Epoch 521/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 25.7796 - accuracy: 2.1753e-04 - val_loss: 22.1201 - val_accuracy: 3.6911e-04\n",
      "Epoch 522/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 25.7658 - accuracy: 2.0744e-04 - val_loss: 15.2165 - val_accuracy: 1.4765e-04\n",
      "Epoch 523/1000\n",
      "10847/10847 [==============================] - 10s 888us/step - loss: 25.7780 - accuracy: 2.3049e-04 - val_loss: 15.1816 - val_accuracy: 3.6911e-04\n",
      "Epoch 524/1000\n",
      "10847/10847 [==============================] - 10s 876us/step - loss: 25.7545 - accuracy: 2.2185e-04 - val_loss: 18.9414 - val_accuracy: 3.6911e-04\n",
      "Epoch 525/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7087 - accuracy: 2.1753e-04 - val_loss: 16.3032 - val_accuracy: 3.6911e-04\n",
      "Epoch 526/1000\n",
      "10847/10847 [==============================] - 10s 880us/step - loss: 25.7635 - accuracy: 2.2761e-04 - val_loss: 19.3085 - val_accuracy: 0.0012\n",
      "Epoch 527/1000\n",
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7511 - accuracy: 2.2329e-04 - val_loss: 16.7590 - val_accuracy: 4.0602e-04\n",
      "Epoch 528/1000\n",
      "10847/10847 [==============================] - 9s 875us/step - loss: 25.6808 - accuracy: 2.2905e-04 - val_loss: 18.7467 - val_accuracy: 3.6911e-04\n",
      "Epoch 529/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 25.7195 - accuracy: 2.1465e-04 - val_loss: 17.1161 - val_accuracy: 3.6911e-04\n",
      "Epoch 530/1000\n",
      "10847/10847 [==============================] - 10s 879us/step - loss: 25.7169 - accuracy: 2.1320e-04 - val_loss: 15.5425 - val_accuracy: 3.6911e-04\n",
      "Epoch 531/1000\n",
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7226 - accuracy: 2.3193e-04 - val_loss: 16.8047 - val_accuracy: 3.6911e-04\n",
      "Epoch 532/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7549 - accuracy: 2.1320e-04 - val_loss: 15.9155 - val_accuracy: 3.6911e-04\n",
      "Epoch 533/1000\n",
      "10847/10847 [==============================] - 10s 878us/step - loss: 25.7169 - accuracy: 2.1609e-04 - val_loss: 16.2585 - val_accuracy: 3.6911e-04\n",
      "Epoch 534/1000\n",
      "10847/10847 [==============================] - 10s 876us/step - loss: 25.6925 - accuracy: 2.1753e-04 - val_loss: 16.5228 - val_accuracy: 3.6911e-04\n",
      "Epoch 535/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7059 - accuracy: 2.1465e-04 - val_loss: 14.3089 - val_accuracy: 3.6911e-04\n",
      "Epoch 536/1000\n",
      "10847/10847 [==============================] - 10s 884us/step - loss: 25.7452 - accuracy: 2.1032e-04 - val_loss: 17.8746 - val_accuracy: 4.0602e-04\n",
      "Epoch 537/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7138 - accuracy: 2.1032e-04 - val_loss: 17.5369 - val_accuracy: 3.6911e-04\n",
      "Epoch 538/1000\n",
      "10847/10847 [==============================] - 9s 874us/step - loss: 25.7352 - accuracy: 2.4202e-04 - val_loss: 14.7614 - val_accuracy: 3.6911e-04\n",
      "Epoch 539/1000\n",
      "10847/10847 [==============================] - 10s 881us/step - loss: 25.7503 - accuracy: 2.2905e-04 - val_loss: 15.6779 - val_accuracy: 3.6911e-04\n",
      "Epoch 540/1000\n",
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7027 - accuracy: 2.3049e-04 - val_loss: 15.7896 - val_accuracy: 3.6911e-04\n",
      "Epoch 541/1000\n",
      "10847/10847 [==============================] - 10s 880us/step - loss: 25.7415 - accuracy: 2.1609e-04 - val_loss: 18.2071 - val_accuracy: 3.6911e-04\n",
      "Epoch 542/1000\n",
      "10847/10847 [==============================] - 10s 879us/step - loss: 25.7284 - accuracy: 2.2473e-04 - val_loss: 17.2541 - val_accuracy: 3.6911e-04\n",
      "Epoch 543/1000\n",
      "10847/10847 [==============================] - 9s 873us/step - loss: 25.7224 - accuracy: 2.2185e-04 - val_loss: 17.5023 - val_accuracy: 3.6911e-04\n",
      "Epoch 544/1000\n",
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7261 - accuracy: 2.0600e-04 - val_loss: 17.3659 - val_accuracy: 3.6911e-04\n",
      "Epoch 545/1000\n",
      "10847/10847 [==============================] - 9s 875us/step - loss: 25.7289 - accuracy: 2.0024e-04 - val_loss: 15.8045 - val_accuracy: 3.6911e-04\n",
      "Epoch 546/1000\n",
      "10847/10847 [==============================] - 10s 879us/step - loss: 25.7324 - accuracy: 2.1032e-04 - val_loss: 15.9228 - val_accuracy: 3.6911e-04\n",
      "Epoch 547/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7637 - accuracy: 2.1897e-04 - val_loss: 16.1649 - val_accuracy: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "10847/10847 [==============================] - 10s 879us/step - loss: 25.6779 - accuracy: 2.1897e-04 - val_loss: 15.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "10847/10847 [==============================] - 9s 868us/step - loss: 25.7009 - accuracy: 2.1176e-04 - val_loss: 16.6780 - val_accuracy: 4.0602e-04\n",
      "Epoch 550/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7053 - accuracy: 2.2473e-04 - val_loss: 14.2402 - val_accuracy: 3.6911e-04\n",
      "Epoch 551/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7221 - accuracy: 2.1320e-04 - val_loss: 15.5520 - val_accuracy: 3.6911e-04\n",
      "Epoch 552/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 25.6734 - accuracy: 2.1609e-04 - val_loss: 16.6759 - val_accuracy: 3.6911e-04\n",
      "Epoch 553/1000\n",
      "10847/10847 [==============================] - 10s 877us/step - loss: 25.7208 - accuracy: 1.9448e-04 - val_loss: 14.8965 - val_accuracy: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7333 - accuracy: 2.1032e-04 - val_loss: 14.9412 - val_accuracy: 3.6911e-04\n",
      "Epoch 555/1000\n",
      "10847/10847 [==============================] - 9s 858us/step - loss: 25.7401 - accuracy: 2.1465e-04 - val_loss: 14.4493 - val_accuracy: 3.6911e-04\n",
      "Epoch 556/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.7890 - accuracy: 2.2617e-04 - val_loss: 14.9707 - val_accuracy: 3.6911e-04\n",
      "Epoch 557/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.7422 - accuracy: 2.2617e-04 - val_loss: 15.5413 - val_accuracy: 3.6911e-04\n",
      "Epoch 558/1000\n",
      "10847/10847 [==============================] - 9s 861us/step - loss: 25.7648 - accuracy: 2.2041e-04 - val_loss: 17.8915 - val_accuracy: 3.6911e-04\n",
      "Epoch 559/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7458 - accuracy: 2.1176e-04 - val_loss: 16.4480 - val_accuracy: 3.6911e-04\n",
      "Epoch 560/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7129 - accuracy: 2.0456e-04 - val_loss: 16.2039 - val_accuracy: 3.6911e-04\n",
      "Epoch 561/1000\n",
      "10847/10847 [==============================] - 9s 869us/step - loss: 25.7437 - accuracy: 2.1897e-04 - val_loss: 14.5408 - val_accuracy: 3.6911e-04\n",
      "Epoch 562/1000\n",
      "10847/10847 [==============================] - 9s 859us/step - loss: 25.7585 - accuracy: 2.1032e-04 - val_loss: 16.0021 - val_accuracy: 3.6911e-04\n",
      "Epoch 563/1000\n",
      "10847/10847 [==============================] - 9s 865us/step - loss: 25.7476 - accuracy: 2.1320e-04 - val_loss: 17.3262 - val_accuracy: 3.6911e-04\n",
      "Epoch 564/1000\n",
      "10847/10847 [==============================] - 10s 897us/step - loss: 25.7608 - accuracy: 2.1176e-04 - val_loss: 17.7933 - val_accuracy: 3.6911e-04\n",
      "Epoch 565/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7513 - accuracy: 2.3049e-04 - val_loss: 15.6176 - val_accuracy: 3.6911e-04\n",
      "Epoch 566/1000\n",
      "10847/10847 [==============================] - 10s 896us/step - loss: 25.7208 - accuracy: 2.3193e-04 - val_loss: 14.7937 - val_accuracy: 3.6911e-04\n",
      "Epoch 567/1000\n",
      "10847/10847 [==============================] - 10s 908us/step - loss: 25.7130 - accuracy: 2.2473e-04 - val_loss: 16.1207 - val_accuracy: 3.6911e-04\n",
      "Epoch 568/1000\n",
      "10847/10847 [==============================] - 10s 926us/step - loss: 25.6900 - accuracy: 2.2761e-04 - val_loss: 14.7697 - val_accuracy: 3.6911e-04\n",
      "Epoch 569/1000\n",
      "10847/10847 [==============================] - 10s 892us/step - loss: 25.7219 - accuracy: 2.1753e-04 - val_loss: 16.6002 - val_accuracy: 3.6911e-04\n",
      "Epoch 570/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 25.7208 - accuracy: 2.1897e-04 - val_loss: 16.6280 - val_accuracy: 4.0602e-04\n",
      "Epoch 571/1000\n",
      "10847/10847 [==============================] - 9s 872us/step - loss: 25.7568 - accuracy: 2.2905e-04 - val_loss: 14.5696 - val_accuracy: 3.6911e-04\n",
      "Epoch 572/1000\n",
      "10847/10847 [==============================] - 10s 888us/step - loss: 25.7463 - accuracy: 2.1176e-04 - val_loss: 15.8547 - val_accuracy: 3.6911e-04\n",
      "Epoch 573/1000\n",
      "10847/10847 [==============================] - 10s 912us/step - loss: 25.7339 - accuracy: 2.2761e-04 - val_loss: 15.8527 - val_accuracy: 3.6911e-04\n",
      "Epoch 574/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7700 - accuracy: 2.2329e-04 - val_loss: 14.8831 - val_accuracy: 3.6911e-04\n",
      "Epoch 575/1000\n",
      "10847/10847 [==============================] - 10s 928us/step - loss: 25.7595 - accuracy: 2.0168e-04 - val_loss: 14.7550 - val_accuracy: 3.6911e-04\n",
      "Epoch 576/1000\n",
      "10847/10847 [==============================] - 11s 982us/step - loss: 25.7486 - accuracy: 2.3193e-04 - val_loss: 16.4475 - val_accuracy: 3.6911e-04\n",
      "Epoch 577/1000\n",
      "10847/10847 [==============================] - 10s 964us/step - loss: 25.7525 - accuracy: 2.0744e-04 - val_loss: 15.7798 - val_accuracy: 0.0000e+00\n",
      "Epoch 578/1000\n",
      "10847/10847 [==============================] - 10s 926us/step - loss: 25.7269 - accuracy: 2.2473e-04 - val_loss: 14.0197 - val_accuracy: 3.6911e-04\n",
      "Epoch 579/1000\n",
      "10847/10847 [==============================] - 10s 924us/step - loss: 25.7083 - accuracy: 2.2185e-04 - val_loss: 14.3625 - val_accuracy: 3.6911e-04\n",
      "Epoch 580/1000\n",
      "10847/10847 [==============================] - 10s 931us/step - loss: 25.7636 - accuracy: 2.0600e-04 - val_loss: 14.7477 - val_accuracy: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "10847/10847 [==============================] - 10s 912us/step - loss: 25.7493 - accuracy: 2.1897e-04 - val_loss: 14.2686 - val_accuracy: 3.6911e-04\n",
      "Epoch 582/1000\n",
      "10847/10847 [==============================] - 10s 952us/step - loss: 25.7499 - accuracy: 2.0744e-04 - val_loss: 14.5280 - val_accuracy: 0.0000e+00\n",
      "Epoch 583/1000\n",
      "10847/10847 [==============================] - 10s 887us/step - loss: 25.6869 - accuracy: 2.1320e-04 - val_loss: 15.1929 - val_accuracy: 3.6911e-04\n",
      "Epoch 584/1000\n",
      "10847/10847 [==============================] - 10s 909us/step - loss: 25.7714 - accuracy: 2.1032e-04 - val_loss: 16.6123 - val_accuracy: 3.6911e-04\n",
      "Epoch 585/1000\n",
      "10847/10847 [==============================] - 10s 953us/step - loss: 25.7897 - accuracy: 2.2185e-04 - val_loss: 14.4212 - val_accuracy: 3.6911e-04\n",
      "Epoch 586/1000\n",
      "10847/10847 [==============================] - 10s 946us/step - loss: 25.7731 - accuracy: 2.2473e-04 - val_loss: 19.2619 - val_accuracy: 3.6911e-04\n",
      "Epoch 587/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7356 - accuracy: 1.9592e-04 - val_loss: 15.4047 - val_accuracy: 3.6911e-04\n",
      "Epoch 588/1000\n",
      "10847/10847 [==============================] - 9s 870us/step - loss: 25.7355 - accuracy: 2.1320e-04 - val_loss: 14.4588 - val_accuracy: 0.0000e+00\n",
      "Epoch 589/1000\n",
      "10847/10847 [==============================] - 10s 927us/step - loss: 25.7334 - accuracy: 1.9736e-04 - val_loss: 18.3467 - val_accuracy: 4.0602e-04\n",
      "Epoch 590/1000\n",
      "10847/10847 [==============================] - 11s 981us/step - loss: 25.7401 - accuracy: 2.1609e-04 - val_loss: 17.2134 - val_accuracy: 3.6911e-04\n",
      "Epoch 591/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7371 - accuracy: 2.1032e-04 - val_loss: 16.7755 - val_accuracy: 0.0000e+00\n",
      "Epoch 592/1000\n",
      "10847/10847 [==============================] - 11s 987us/step - loss: 25.7553 - accuracy: 2.0600e-04 - val_loss: 15.2033 - val_accuracy: 3.6911e-04\n",
      "Epoch 593/1000\n",
      "10847/10847 [==============================] - 11s 982us/step - loss: 25.7082 - accuracy: 2.2617e-04 - val_loss: 14.9883 - val_accuracy: 3.6911e-04\n",
      "Epoch 594/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7520 - accuracy: 2.1465e-04 - val_loss: 16.9364 - val_accuracy: 3.6911e-04\n",
      "Epoch 595/1000\n",
      "10847/10847 [==============================] - 11s 986us/step - loss: 25.7378 - accuracy: 2.3049e-04 - val_loss: 20.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 596/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7615 - accuracy: 2.1897e-04 - val_loss: 15.4363 - val_accuracy: 3.6911e-04\n",
      "Epoch 597/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7667 - accuracy: 2.0456e-04 - val_loss: 16.7261 - val_accuracy: 3.6911e-04\n",
      "Epoch 598/1000\n",
      "10847/10847 [==============================] - 11s 984us/step - loss: 25.7063 - accuracy: 2.4058e-04 - val_loss: 13.9746 - val_accuracy: 0.0000e+00\n",
      "Epoch 599/1000\n",
      "10847/10847 [==============================] - 10s 920us/step - loss: 25.7528 - accuracy: 2.2905e-04 - val_loss: 17.0283 - val_accuracy: 3.6911e-04\n",
      "Epoch 600/1000\n",
      "10847/10847 [==============================] - 10s 968us/step - loss: 25.6917 - accuracy: 2.1609e-04 - val_loss: 18.4663 - val_accuracy: 3.6911e-04\n",
      "Epoch 601/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.6914 - accuracy: 2.2761e-04 - val_loss: 15.6597 - val_accuracy: 3.6911e-04\n",
      "Epoch 602/1000\n",
      "10847/10847 [==============================] - 12s 1ms/step - loss: 25.7499 - accuracy: 2.0456e-04 - val_loss: 19.2497 - val_accuracy: 3.6911e-04\n",
      "Epoch 603/1000\n",
      "10847/10847 [==============================] - 12s 1ms/step - loss: 25.7355 - accuracy: 2.2041e-04 - val_loss: 18.2855 - val_accuracy: 3.6911e-04\n",
      "Epoch 604/1000\n",
      "10847/10847 [==============================] - 10s 935us/step - loss: 25.7151 - accuracy: 1.8872e-04 - val_loss: 15.3782 - val_accuracy: 3.6911e-04\n",
      "Epoch 605/1000\n",
      "10847/10847 [==============================] - 10s 941us/step - loss: 25.7424 - accuracy: 2.2185e-04 - val_loss: 15.0810 - val_accuracy: 3.6911e-04\n",
      "Epoch 606/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7560 - accuracy: 2.0600e-04 - val_loss: 16.4182 - val_accuracy: 3.6911e-04\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 10s 915us/step - loss: 25.7298 - accuracy: 1.7863e-04 - val_loss: 13.9763 - val_accuracy: 0.0000e+00\n",
      "Epoch 608/1000\n",
      "10847/10847 [==============================] - 10s 917us/step - loss: 25.7450 - accuracy: 2.1176e-04 - val_loss: 17.3483 - val_accuracy: 4.0602e-04\n",
      "Epoch 609/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 25.7315 - accuracy: 2.1032e-04 - val_loss: 17.4532 - val_accuracy: 4.0602e-04\n",
      "Epoch 610/1000\n",
      "10847/10847 [==============================] - 10s 906us/step - loss: 25.7303 - accuracy: 2.0888e-04 - val_loss: 14.7281 - val_accuracy: 3.6911e-04\n",
      "Epoch 611/1000\n",
      "10847/10847 [==============================] - 10s 895us/step - loss: 25.7072 - accuracy: 2.1897e-04 - val_loss: 16.1886 - val_accuracy: 3.6911e-04\n",
      "Epoch 612/1000\n",
      "10847/10847 [==============================] - 10s 900us/step - loss: 25.7020 - accuracy: 2.1032e-04 - val_loss: 15.5745 - val_accuracy: 3.6911e-04\n",
      "Epoch 613/1000\n",
      "10847/10847 [==============================] - 10s 893us/step - loss: 25.6986 - accuracy: 2.1897e-04 - val_loss: 16.5934 - val_accuracy: 3.6911e-04\n",
      "Epoch 614/1000\n",
      "10847/10847 [==============================] - 10s 921us/step - loss: 25.7198 - accuracy: 2.1032e-04 - val_loss: 14.7915 - val_accuracy: 0.0000e+00\n",
      "Epoch 615/1000\n",
      "10847/10847 [==============================] - 10s 923us/step - loss: 25.6892 - accuracy: 2.2041e-04 - val_loss: 15.1866 - val_accuracy: 3.6911e-04\n",
      "Epoch 616/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7513 - accuracy: 2.0456e-04 - val_loss: 14.0833 - val_accuracy: 3.6911e-04\n",
      "Epoch 617/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 25.7231 - accuracy: 2.1609e-04 - val_loss: 16.7185 - val_accuracy: 2.2147e-04\n",
      "Epoch 618/1000\n",
      "10847/10847 [==============================] - 10s 905us/step - loss: 25.7063 - accuracy: 2.0888e-04 - val_loss: 15.9974 - val_accuracy: 0.0000e+00\n",
      "Epoch 619/1000\n",
      "10847/10847 [==============================] - 10s 901us/step - loss: 25.7195 - accuracy: 2.2041e-04 - val_loss: 15.0478 - val_accuracy: 3.6911e-04\n",
      "Epoch 620/1000\n",
      "10847/10847 [==============================] - 10s 901us/step - loss: 25.7402 - accuracy: 2.3049e-04 - val_loss: 15.6599 - val_accuracy: 0.0000e+00\n",
      "Epoch 621/1000\n",
      "10847/10847 [==============================] - 10s 897us/step - loss: 25.6952 - accuracy: 2.0312e-04 - val_loss: 14.5397 - val_accuracy: 3.6911e-04\n",
      "Epoch 622/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7726 - accuracy: 2.1609e-04 - val_loss: 14.4650 - val_accuracy: 3.6911e-04\n",
      "Epoch 623/1000\n",
      "10847/10847 [==============================] - 10s 898us/step - loss: 25.7714 - accuracy: 1.8439e-04 - val_loss: 13.5408 - val_accuracy: 3.6911e-04\n",
      "Epoch 624/1000\n",
      "10847/10847 [==============================] - 10s 895us/step - loss: 25.7244 - accuracy: 1.9592e-04 - val_loss: 17.1463 - val_accuracy: 3.6911e-04\n",
      "Epoch 625/1000\n",
      "10847/10847 [==============================] - 10s 901us/step - loss: 25.7146 - accuracy: 2.3049e-04 - val_loss: 16.6936 - val_accuracy: 4.0602e-04\n",
      "Epoch 626/1000\n",
      "10847/10847 [==============================] - 10s 899us/step - loss: 25.7560 - accuracy: 2.1320e-04 - val_loss: 14.6107 - val_accuracy: 3.6911e-04\n",
      "Epoch 627/1000\n",
      "10847/10847 [==============================] - 10s 903us/step - loss: 25.7649 - accuracy: 2.1176e-04 - val_loss: 14.3815 - val_accuracy: 3.6911e-04\n",
      "Epoch 628/1000\n",
      "10847/10847 [==============================] - 10s 944us/step - loss: 25.7910 - accuracy: 2.1176e-04 - val_loss: 14.6575 - val_accuracy: 3.6911e-04\n",
      "Epoch 629/1000\n",
      "10847/10847 [==============================] - 10s 896us/step - loss: 25.7730 - accuracy: 2.1465e-04 - val_loss: 14.1169 - val_accuracy: 3.6911e-04\n",
      "Epoch 630/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 25.7185 - accuracy: 2.1176e-04 - val_loss: 14.6694 - val_accuracy: 3.6911e-04\n",
      "Epoch 631/1000\n",
      "10847/10847 [==============================] - 10s 891us/step - loss: 25.7543 - accuracy: 2.2329e-04 - val_loss: 16.2007 - val_accuracy: 3.6911e-04\n",
      "Epoch 632/1000\n",
      "10847/10847 [==============================] - 10s 899us/step - loss: 25.6906 - accuracy: 2.2041e-04 - val_loss: 13.6834 - val_accuracy: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "10847/10847 [==============================] - 10s 903us/step - loss: 25.7331 - accuracy: 2.0888e-04 - val_loss: 15.9283 - val_accuracy: 3.6911e-04\n",
      "Epoch 634/1000\n",
      "10847/10847 [==============================] - 10s 895us/step - loss: 25.7461 - accuracy: 2.0600e-04 - val_loss: 17.6470 - val_accuracy: 3.6911e-04\n",
      "Epoch 635/1000\n",
      "10847/10847 [==============================] - 10s 897us/step - loss: 25.7298 - accuracy: 1.9448e-04 - val_loss: 15.9387 - val_accuracy: 3.6911e-04\n",
      "Epoch 636/1000\n",
      "10847/10847 [==============================] - 10s 903us/step - loss: 25.7827 - accuracy: 1.9592e-04 - val_loss: 13.3283 - val_accuracy: 0.0000e+00\n",
      "Epoch 637/1000\n",
      "10847/10847 [==============================] - 10s 922us/step - loss: 25.7545 - accuracy: 2.2041e-04 - val_loss: 12.8507 - val_accuracy: 3.6911e-04\n",
      "Epoch 638/1000\n",
      "10847/10847 [==============================] - 10s 935us/step - loss: 25.7237 - accuracy: 2.1897e-04 - val_loss: 17.6483 - val_accuracy: 3.6911e-04\n",
      "Epoch 639/1000\n",
      "10847/10847 [==============================] - 10s 946us/step - loss: 25.7503 - accuracy: 2.1176e-04 - val_loss: 15.4239 - val_accuracy: 3.6911e-04\n",
      "Epoch 640/1000\n",
      "10847/10847 [==============================] - 10s 913us/step - loss: 25.7368 - accuracy: 2.0888e-04 - val_loss: 17.2825 - val_accuracy: 3.6911e-04\n",
      "Epoch 641/1000\n",
      "10847/10847 [==============================] - 10s 929us/step - loss: 25.7494 - accuracy: 2.1465e-04 - val_loss: 13.7869 - val_accuracy: 3.6911e-04\n",
      "Epoch 642/1000\n",
      "10847/10847 [==============================] - 10s 952us/step - loss: 25.6886 - accuracy: 2.0744e-04 - val_loss: 17.3918 - val_accuracy: 3.6911e-04\n",
      "Epoch 643/1000\n",
      "10847/10847 [==============================] - 10s 937us/step - loss: 25.7366 - accuracy: 2.2041e-04 - val_loss: 14.9060 - val_accuracy: 3.6911e-04\n",
      "Epoch 644/1000\n",
      "10847/10847 [==============================] - 10s 906us/step - loss: 25.7219 - accuracy: 2.1465e-04 - val_loss: 15.4286 - val_accuracy: 3.6911e-04\n",
      "Epoch 645/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7772 - accuracy: 2.1897e-04 - val_loss: 16.7856 - val_accuracy: 3.6911e-04\n",
      "Epoch 646/1000\n",
      "10847/10847 [==============================] - 10s 914us/step - loss: 25.7153 - accuracy: 2.2185e-04 - val_loss: 13.8294 - val_accuracy: 3.6911e-04\n",
      "Epoch 647/1000\n",
      "10847/10847 [==============================] - 10s 916us/step - loss: 25.7382 - accuracy: 2.0600e-04 - val_loss: 19.4925 - val_accuracy: 4.0602e-04\n",
      "Epoch 648/1000\n",
      "10847/10847 [==============================] - 10s 903us/step - loss: 25.7265 - accuracy: 2.1897e-04 - val_loss: 17.8851 - val_accuracy: 3.6911e-04\n",
      "Epoch 649/1000\n",
      "10847/10847 [==============================] - 10s 911us/step - loss: 25.7672 - accuracy: 1.9592e-04 - val_loss: 17.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 650/1000\n",
      "10847/10847 [==============================] - 10s 932us/step - loss: 25.7769 - accuracy: 2.0312e-04 - val_loss: 14.3534 - val_accuracy: 3.6911e-04\n",
      "Epoch 651/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7818 - accuracy: 2.1032e-04 - val_loss: 15.7406 - val_accuracy: 3.6911e-04\n",
      "Epoch 652/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7884 - accuracy: 2.1320e-04 - val_loss: 17.4000 - val_accuracy: 3.6911e-04\n",
      "Epoch 653/1000\n",
      "10847/10847 [==============================] - 10s 946us/step - loss: 25.7368 - accuracy: 1.8295e-04 - val_loss: 18.5786 - val_accuracy: 3.6911e-04\n",
      "Epoch 654/1000\n",
      "10847/10847 [==============================] - 10s 962us/step - loss: 25.7668 - accuracy: 2.0744e-04 - val_loss: 17.0237 - val_accuracy: 3.6911e-04\n",
      "Epoch 655/1000\n",
      "10847/10847 [==============================] - 11s 981us/step - loss: 25.8043 - accuracy: 2.0168e-04 - val_loss: 16.9593 - val_accuracy: 3.6911e-04\n",
      "Epoch 656/1000\n",
      "10847/10847 [==============================] - 10s 957us/step - loss: 25.8037 - accuracy: 2.0312e-04 - val_loss: 15.1402 - val_accuracy: 3.6911e-04\n",
      "Epoch 657/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 11s 997us/step - loss: 25.7933 - accuracy: 2.0312e-04 - val_loss: 16.5436 - val_accuracy: 3.6911e-04\n",
      "Epoch 658/1000\n",
      "10847/10847 [==============================] - 10s 933us/step - loss: 25.8126 - accuracy: 2.2329e-04 - val_loss: 14.9203 - val_accuracy: 3.6911e-04\n",
      "Epoch 659/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7279 - accuracy: 2.1176e-04 - val_loss: 14.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "10847/10847 [==============================] - 10s 958us/step - loss: 25.8027 - accuracy: 2.0024e-04 - val_loss: 15.4076 - val_accuracy: 0.0000e+00\n",
      "Epoch 661/1000\n",
      "10847/10847 [==============================] - 11s 969us/step - loss: 25.7094 - accuracy: 1.8439e-04 - val_loss: 15.6625 - val_accuracy: 3.6911e-04\n",
      "Epoch 662/1000\n",
      "10847/10847 [==============================] - 11s 996us/step - loss: 25.7408 - accuracy: 2.1176e-04 - val_loss: 17.3974 - val_accuracy: 3.6911e-04\n",
      "Epoch 663/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7663 - accuracy: 2.0600e-04 - val_loss: 14.5780 - val_accuracy: 3.6911e-04\n",
      "Epoch 664/1000\n",
      "10847/10847 [==============================] - 11s 975us/step - loss: 25.7969 - accuracy: 2.0168e-04 - val_loss: 13.6540 - val_accuracy: 3.6911e-04\n",
      "Epoch 665/1000\n",
      "10847/10847 [==============================] - 11s 990us/step - loss: 25.7755 - accuracy: 2.0168e-04 - val_loss: 15.4072 - val_accuracy: 3.6911e-04\n",
      "Epoch 666/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7866 - accuracy: 2.2473e-04 - val_loss: 16.1504 - val_accuracy: 3.6911e-04\n",
      "Epoch 667/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 25.7395 - accuracy: 2.0312e-04 - val_loss: 17.1038 - val_accuracy: 3.6911e-04\n",
      "Epoch 668/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 25.7255 - accuracy: 1.9880e-04 - val_loss: 14.4045 - val_accuracy: 0.0000e+00\n",
      "Epoch 669/1000\n",
      "10847/10847 [==============================] - 10s 901us/step - loss: 25.7445 - accuracy: 2.1032e-04 - val_loss: 17.5432 - val_accuracy: 3.6911e-04\n",
      "Epoch 670/1000\n",
      "10847/10847 [==============================] - 10s 899us/step - loss: 25.7502 - accuracy: 2.2041e-04 - val_loss: 15.5663 - val_accuracy: 3.6911e-04\n",
      "Epoch 671/1000\n",
      "10847/10847 [==============================] - 10s 897us/step - loss: 25.7890 - accuracy: 2.0456e-04 - val_loss: 15.3609 - val_accuracy: 3.6911e-04\n",
      "Epoch 672/1000\n",
      "10847/10847 [==============================] - 10s 892us/step - loss: 25.7695 - accuracy: 1.9448e-04 - val_loss: 14.7737 - val_accuracy: 3.6911e-04\n",
      "Epoch 673/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 25.7601 - accuracy: 2.1897e-04 - val_loss: 15.4803 - val_accuracy: 3.6911e-04\n",
      "Epoch 674/1000\n",
      "10847/10847 [==============================] - 10s 909us/step - loss: 25.7608 - accuracy: 2.0888e-04 - val_loss: 16.0248 - val_accuracy: 0.0000e+00\n",
      "Epoch 675/1000\n",
      "10847/10847 [==============================] - 10s 896us/step - loss: 25.7580 - accuracy: 2.0456e-04 - val_loss: 13.1398 - val_accuracy: 3.6911e-04\n",
      "Epoch 676/1000\n",
      "10847/10847 [==============================] - 10s 916us/step - loss: 25.7376 - accuracy: 2.1465e-04 - val_loss: 14.9694 - val_accuracy: 3.6911e-04\n",
      "Epoch 677/1000\n",
      "10847/10847 [==============================] - 10s 908us/step - loss: 25.7134 - accuracy: 2.1176e-04 - val_loss: 15.1244 - val_accuracy: 3.6911e-04\n",
      "Epoch 678/1000\n",
      "10847/10847 [==============================] - 10s 897us/step - loss: 25.7628 - accuracy: 1.8439e-04 - val_loss: 16.9796 - val_accuracy: 3.6911e-04\n",
      "Epoch 679/1000\n",
      "10847/10847 [==============================] - 10s 909us/step - loss: 25.7284 - accuracy: 2.0744e-04 - val_loss: 15.5142 - val_accuracy: 3.6911e-04\n",
      "Epoch 680/1000\n",
      "10847/10847 [==============================] - 10s 897us/step - loss: 25.7447 - accuracy: 2.0456e-04 - val_loss: 16.2756 - val_accuracy: 3.6911e-04\n",
      "Epoch 681/1000\n",
      "10847/10847 [==============================] - 10s 906us/step - loss: 25.8062 - accuracy: 2.1320e-04 - val_loss: 15.2927 - val_accuracy: 3.6911e-04\n",
      "Epoch 682/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7842 - accuracy: 2.0888e-04 - val_loss: 15.1800 - val_accuracy: 3.6911e-04\n",
      "Epoch 683/1000\n",
      "10847/10847 [==============================] - 10s 894us/step - loss: 25.7415 - accuracy: 2.1753e-04 - val_loss: 15.2766 - val_accuracy: 3.6911e-04\n",
      "Epoch 684/1000\n",
      "10847/10847 [==============================] - 10s 907us/step - loss: 25.7303 - accuracy: 2.0744e-04 - val_loss: 14.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 685/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7399 - accuracy: 2.1320e-04 - val_loss: 14.3487 - val_accuracy: 0.0000e+00\n",
      "Epoch 686/1000\n",
      "10847/10847 [==============================] - 10s 902us/step - loss: 25.7807 - accuracy: 2.0168e-04 - val_loss: 15.1740 - val_accuracy: 3.6911e-04\n",
      "Epoch 687/1000\n",
      "10847/10847 [==============================] - 10s 905us/step - loss: 25.7602 - accuracy: 2.0600e-04 - val_loss: 14.5614 - val_accuracy: 0.0000e+00\n",
      "Epoch 688/1000\n",
      "10847/10847 [==============================] - 10s 911us/step - loss: 25.7681 - accuracy: 2.0024e-04 - val_loss: 15.7643 - val_accuracy: 3.6911e-04\n",
      "Epoch 689/1000\n",
      "10847/10847 [==============================] - 10s 903us/step - loss: 25.7848 - accuracy: 1.9448e-04 - val_loss: 14.7070 - val_accuracy: 3.6911e-04\n",
      "Epoch 690/1000\n",
      "10847/10847 [==============================] - 10s 903us/step - loss: 25.7836 - accuracy: 2.1320e-04 - val_loss: 15.8779 - val_accuracy: 3.6911e-04\n",
      "Epoch 691/1000\n",
      "10847/10847 [==============================] - 10s 896us/step - loss: 25.7680 - accuracy: 2.1320e-04 - val_loss: 14.9710 - val_accuracy: 3.6911e-04\n",
      "Epoch 692/1000\n",
      "10847/10847 [==============================] - 10s 906us/step - loss: 25.7828 - accuracy: 2.0600e-04 - val_loss: 15.2845 - val_accuracy: 3.6911e-04\n",
      "Epoch 693/1000\n",
      "10847/10847 [==============================] - 10s 906us/step - loss: 25.7628 - accuracy: 2.1320e-04 - val_loss: 15.1364 - val_accuracy: 3.6911e-04\n",
      "Epoch 694/1000\n",
      "10847/10847 [==============================] - 10s 954us/step - loss: 25.7765 - accuracy: 1.8151e-04 - val_loss: 17.4569 - val_accuracy: 3.6911e-04\n",
      "Epoch 695/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7400 - accuracy: 2.0456e-04 - val_loss: 16.0445 - val_accuracy: 3.6911e-04\n",
      "Epoch 696/1000\n",
      "10847/10847 [==============================] - 10s 967us/step - loss: 25.7288 - accuracy: 2.2761e-04 - val_loss: 15.6239 - val_accuracy: 3.6911e-04\n",
      "Epoch 697/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7595 - accuracy: 2.0312e-04 - val_loss: 14.3128 - val_accuracy: 0.0000e+00\n",
      "Epoch 698/1000\n",
      "10847/10847 [==============================] - 11s 990us/step - loss: 25.7516 - accuracy: 2.2041e-04 - val_loss: 16.2078 - val_accuracy: 3.6911e-04\n",
      "Epoch 699/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7498 - accuracy: 2.0888e-04 - val_loss: 15.3288 - val_accuracy: 3.6911e-04\n",
      "Epoch 700/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7925 - accuracy: 1.9880e-04 - val_loss: 16.3613 - val_accuracy: 3.6911e-04\n",
      "Epoch 701/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7781 - accuracy: 2.1320e-04 - val_loss: 17.0769 - val_accuracy: 3.6911e-04\n",
      "Epoch 702/1000\n",
      "10847/10847 [==============================] - 11s 969us/step - loss: 25.7800 - accuracy: 2.1032e-04 - val_loss: 17.2427 - val_accuracy: 3.6911e-04\n",
      "Epoch 703/1000\n",
      "10847/10847 [==============================] - 10s 947us/step - loss: 25.7313 - accuracy: 2.0456e-04 - val_loss: 15.4027 - val_accuracy: 3.6911e-04\n",
      "Epoch 704/1000\n",
      "10847/10847 [==============================] - 10s 924us/step - loss: 25.7435 - accuracy: 2.0744e-04 - val_loss: 16.3288 - val_accuracy: 3.6911e-04\n",
      "Epoch 705/1000\n",
      "10847/10847 [==============================] - 10s 922us/step - loss: 25.7161 - accuracy: 2.0600e-04 - val_loss: 15.1765 - val_accuracy: 3.6911e-04\n",
      "Epoch 706/1000\n",
      "10847/10847 [==============================] - 10s 935us/step - loss: 25.7902 - accuracy: 2.1753e-04 - val_loss: 17.2776 - val_accuracy: 0.0000e+00\n",
      "Epoch 707/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 10s 931us/step - loss: 25.7677 - accuracy: 2.1176e-04 - val_loss: 15.9907 - val_accuracy: 3.6911e-04\n",
      "Epoch 708/1000\n",
      "10847/10847 [==============================] - 10s 896us/step - loss: 25.7153 - accuracy: 2.0600e-04 - val_loss: 16.6208 - val_accuracy: 3.6911e-04\n",
      "Epoch 709/1000\n",
      "10847/10847 [==============================] - 10s 921us/step - loss: 25.7582 - accuracy: 1.8727e-04 - val_loss: 15.9225 - val_accuracy: 3.6911e-04\n",
      "Epoch 710/1000\n",
      "10847/10847 [==============================] - 10s 925us/step - loss: 25.7546 - accuracy: 2.1032e-04 - val_loss: 13.7528 - val_accuracy: 0.0000e+00\n",
      "Epoch 711/1000\n",
      "10847/10847 [==============================] - 10s 914us/step - loss: 25.8147 - accuracy: 2.0456e-04 - val_loss: 14.4168 - val_accuracy: 3.6911e-04\n",
      "Epoch 712/1000\n",
      "10847/10847 [==============================] - 10s 912us/step - loss: 25.7547 - accuracy: 2.2185e-04 - val_loss: 18.2353 - val_accuracy: 4.0602e-04\n",
      "Epoch 713/1000\n",
      "10847/10847 [==============================] - 11s 996us/step - loss: 25.7433 - accuracy: 2.1032e-04 - val_loss: 15.4025 - val_accuracy: 3.6911e-04\n",
      "Epoch 714/1000\n",
      "10847/10847 [==============================] - 10s 959us/step - loss: 25.7614 - accuracy: 2.0600e-04 - val_loss: 16.6560 - val_accuracy: 0.0000e+00\n",
      "Epoch 715/1000\n",
      "10847/10847 [==============================] - 11s 973us/step - loss: 25.7718 - accuracy: 2.0168e-04 - val_loss: 15.6712 - val_accuracy: 3.6911e-04\n",
      "Epoch 716/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7754 - accuracy: 1.9160e-04 - val_loss: 13.3814 - val_accuracy: 0.0000e+00\n",
      "Epoch 717/1000\n",
      "10847/10847 [==============================] - 11s 974us/step - loss: 25.7899 - accuracy: 2.0888e-04 - val_loss: 14.9421 - val_accuracy: 3.6911e-04\n",
      "Epoch 718/1000\n",
      "10847/10847 [==============================] - 10s 909us/step - loss: 25.7468 - accuracy: 2.1176e-04 - val_loss: 13.6834 - val_accuracy: 0.0000e+00\n",
      "Epoch 719/1000\n",
      "10847/10847 [==============================] - 10s 901us/step - loss: 25.7228 - accuracy: 2.2185e-04 - val_loss: 16.6820 - val_accuracy: 0.0000e+00\n",
      "Epoch 720/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7512 - accuracy: 2.2185e-04 - val_loss: 20.4626 - val_accuracy: 0.0000e+00\n",
      "Epoch 721/1000\n",
      "10847/10847 [==============================] - 10s 922us/step - loss: 25.6923 - accuracy: 2.0456e-04 - val_loss: 18.7195 - val_accuracy: 0.0000e+00\n",
      "Epoch 722/1000\n",
      "10847/10847 [==============================] - 11s 998us/step - loss: 25.6727 - accuracy: 2.1897e-04 - val_loss: 18.3404 - val_accuracy: 7.3823e-05\n",
      "Epoch 723/1000\n",
      "10847/10847 [==============================] - 11s 981us/step - loss: 25.6934 - accuracy: 2.2473e-04 - val_loss: 16.0761 - val_accuracy: 0.0000e+00\n",
      "Epoch 724/1000\n",
      "10847/10847 [==============================] - 10s 949us/step - loss: 25.7119 - accuracy: 2.2473e-04 - val_loss: 13.9555 - val_accuracy: 0.0000e+00\n",
      "Epoch 725/1000\n",
      "10847/10847 [==============================] - 10s 885us/step - loss: 25.6963 - accuracy: 2.2905e-04 - val_loss: 15.9442 - val_accuracy: 3.6911e-05\n",
      "Epoch 726/1000\n",
      "10847/10847 [==============================] - 10s 887us/step - loss: 25.6638 - accuracy: 2.2905e-04 - val_loss: 14.3420 - val_accuracy: 0.0000e+00\n",
      "Epoch 727/1000\n",
      "10847/10847 [==============================] - 11s 978us/step - loss: 25.6600 - accuracy: 2.3481e-04 - val_loss: 19.4482 - val_accuracy: 8.4896e-04\n",
      "Epoch 728/1000\n",
      "10847/10847 [==============================] - 10s 949us/step - loss: 25.7385 - accuracy: 2.5642e-04 - val_loss: 16.1342 - val_accuracy: 8.4896e-04\n",
      "Epoch 729/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.7167 - accuracy: 2.4346e-04 - val_loss: 15.0633 - val_accuracy: 0.0000e+00\n",
      "Epoch 730/1000\n",
      "10847/10847 [==============================] - 12s 1ms/step - loss: 25.6536 - accuracy: 2.3769e-04 - val_loss: 14.2243 - val_accuracy: 0.0000e+00\n",
      "Epoch 731/1000\n",
      "10847/10847 [==============================] - 10s 938us/step - loss: 25.7075 - accuracy: 2.6074e-04 - val_loss: 14.7398 - val_accuracy: 0.0000e+00\n",
      "Epoch 732/1000\n",
      "10847/10847 [==============================] - 10s 916us/step - loss: 25.6829 - accuracy: 2.6795e-04 - val_loss: 16.7781 - val_accuracy: 3.6911e-05\n",
      "Epoch 733/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.6942 - accuracy: 2.6651e-04 - val_loss: 15.4625 - val_accuracy: 0.0000e+00\n",
      "Epoch 734/1000\n",
      "10847/10847 [==============================] - 10s 905us/step - loss: 25.7618 - accuracy: 2.7515e-04 - val_loss: 16.0385 - val_accuracy: 0.0000e+00\n",
      "Epoch 735/1000\n",
      "10847/10847 [==============================] - 10s 963us/step - loss: 25.6869 - accuracy: 2.6651e-04 - val_loss: 16.5387 - val_accuracy: 3.6911e-05\n",
      "Epoch 736/1000\n",
      "10847/10847 [==============================] - 10s 952us/step - loss: 25.7070 - accuracy: 2.8091e-04 - val_loss: 16.4002 - val_accuracy: 0.0000e+00\n",
      "Epoch 737/1000\n",
      "10847/10847 [==============================] - 11s 971us/step - loss: 25.7042 - accuracy: 2.7947e-04 - val_loss: 15.4650 - val_accuracy: 0.0000e+00\n",
      "Epoch 738/1000\n",
      "10847/10847 [==============================] - 11s 985us/step - loss: 25.7320 - accuracy: 2.8091e-04 - val_loss: 15.0446 - val_accuracy: 0.0000e+00\n",
      "Epoch 739/1000\n",
      "10847/10847 [==============================] - 10s 915us/step - loss: 25.7181 - accuracy: 2.6939e-04 - val_loss: 14.9673 - val_accuracy: 0.0000e+00\n",
      "Epoch 740/1000\n",
      "10847/10847 [==============================] - 9s 871us/step - loss: 25.7078 - accuracy: 2.8667e-04 - val_loss: 16.2987 - val_accuracy: 0.0000e+00\n",
      "Epoch 741/1000\n",
      "10847/10847 [==============================] - 10s 900us/step - loss: 25.7038 - accuracy: 2.8091e-04 - val_loss: 14.1436 - val_accuracy: 0.0000e+00\n",
      "Epoch 742/1000\n",
      "10847/10847 [==============================] - 10s 899us/step - loss: 25.6883 - accuracy: 2.7515e-04 - val_loss: 15.1308 - val_accuracy: 0.0000e+00\n",
      "Epoch 743/1000\n",
      "10847/10847 [==============================] - 10s 909us/step - loss: 25.6604 - accuracy: 2.7083e-04 - val_loss: 16.6663 - val_accuracy: 3.6911e-05\n",
      "Epoch 744/1000\n",
      "10847/10847 [==============================] - 10s 890us/step - loss: 25.6795 - accuracy: 2.8956e-04 - val_loss: 16.0473 - val_accuracy: 0.0000e+00\n",
      "Epoch 745/1000\n",
      "10847/10847 [==============================] - 10s 891us/step - loss: 25.6589 - accuracy: 2.9388e-04 - val_loss: 13.8680 - val_accuracy: 0.0000e+00\n",
      "Epoch 746/1000\n",
      "10847/10847 [==============================] - 10s 898us/step - loss: 25.6907 - accuracy: 2.9100e-04 - val_loss: 14.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 747/1000\n",
      "10847/10847 [==============================] - 10s 911us/step - loss: 25.7227 - accuracy: 2.8811e-04 - val_loss: 16.8942 - val_accuracy: 0.0000e+00\n",
      "Epoch 748/1000\n",
      "10847/10847 [==============================] - 10s 913us/step - loss: 25.7161 - accuracy: 2.9244e-04 - val_loss: 16.5578 - val_accuracy: 3.6911e-05\n",
      "Epoch 749/1000\n",
      "10847/10847 [==============================] - 10s 896us/step - loss: 25.6466 - accuracy: 3.0540e-04 - val_loss: 16.8067 - val_accuracy: 8.4896e-04\n",
      "Epoch 750/1000\n",
      "10847/10847 [==============================] - 10s 890us/step - loss: 25.6443 - accuracy: 3.0108e-04 - val_loss: 14.1648 - val_accuracy: 0.0000e+00\n",
      "Epoch 751/1000\n",
      "10847/10847 [==============================] - 10s 924us/step - loss: 25.6610 - accuracy: 3.0396e-04 - val_loss: 15.9395 - val_accuracy: 7.3823e-05\n",
      "Epoch 752/1000\n",
      "10847/10847 [==============================] - 10s 899us/step - loss: 25.6392 - accuracy: 2.7947e-04 - val_loss: 15.4601 - val_accuracy: 0.0000e+00\n",
      "Epoch 753/1000\n",
      "10847/10847 [==============================] - 10s 951us/step - loss: 25.6569 - accuracy: 3.0252e-04 - val_loss: 16.2854 - val_accuracy: 0.0000e+00\n",
      "Epoch 754/1000\n",
      "10847/10847 [==============================] - 10s 934us/step - loss: 25.6734 - accuracy: 2.9676e-04 - val_loss: 14.7730 - val_accuracy: 7.3823e-05\n",
      "Epoch 755/1000\n",
      "10847/10847 [==============================] - 9s 863us/step - loss: 25.7167 - accuracy: 2.9964e-04 - val_loss: 13.1849 - val_accuracy: 0.0000e+00\n",
      "Epoch 756/1000\n",
      "10847/10847 [==============================] - 10s 910us/step - loss: 25.6338 - accuracy: 2.9964e-04 - val_loss: 19.1580 - val_accuracy: 7.3823e-05\n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10847/10847 [==============================] - 10s 947us/step - loss: 25.6351 - accuracy: 3.0252e-04 - val_loss: 17.3184 - val_accuracy: 3.6911e-05\n",
      "Epoch 758/1000\n",
      "10847/10847 [==============================] - 10s 891us/step - loss: 25.6595 - accuracy: 2.9820e-04 - val_loss: 15.6415 - val_accuracy: 3.6911e-05\n",
      "Epoch 759/1000\n",
      "10847/10847 [==============================] - 10s 945us/step - loss: 25.6688 - accuracy: 3.0108e-04 - val_loss: 12.8939 - val_accuracy: 0.0000e+00\n",
      "Epoch 760/1000\n",
      "10847/10847 [==============================] - 10s 917us/step - loss: 25.6482 - accuracy: 2.7659e-04 - val_loss: 18.7368 - val_accuracy: 7.3823e-05\n",
      "Epoch 761/1000\n",
      "10847/10847 [==============================] - 10s 900us/step - loss: 25.6179 - accuracy: 2.9244e-04 - val_loss: 13.5967 - val_accuracy: 0.0000e+00\n",
      "Epoch 762/1000\n",
      "10847/10847 [==============================] - 10s 911us/step - loss: 25.6490 - accuracy: 2.8523e-04 - val_loss: 13.3009 - val_accuracy: 0.0000e+00\n",
      "Epoch 763/1000\n",
      "10847/10847 [==============================] - 10s 909us/step - loss: 25.6638 - accuracy: 2.7227e-04 - val_loss: 16.8591 - val_accuracy: 0.0000e+00\n",
      "Epoch 764/1000\n",
      "10847/10847 [==============================] - 10s 939us/step - loss: 25.6883 - accuracy: 2.7803e-04 - val_loss: 16.9677 - val_accuracy: 0.0000e+00\n",
      "Epoch 765/1000\n",
      "10847/10847 [==============================] - 10s 921us/step - loss: 25.7030 - accuracy: 2.9820e-04 - val_loss: 16.7457 - val_accuracy: 3.6911e-05\n",
      "Epoch 766/1000\n",
      "10847/10847 [==============================] - 10s 923us/step - loss: 25.7176 - accuracy: 3.1405e-04 - val_loss: 15.2926 - val_accuracy: 3.6911e-05\n",
      "Epoch 767/1000\n",
      "10847/10847 [==============================] - 10s 913us/step - loss: 25.7424 - accuracy: 2.8523e-04 - val_loss: 14.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 768/1000\n",
      "10847/10847 [==============================] - 10s 899us/step - loss: 25.6714 - accuracy: 3.0828e-04 - val_loss: 17.1743 - val_accuracy: 3.6911e-05\n",
      "Epoch 769/1000\n",
      "10847/10847 [==============================] - 10s 907us/step - loss: 25.6923 - accuracy: 2.7659e-04 - val_loss: 14.7271 - val_accuracy: 3.6911e-05\n",
      "Epoch 770/1000\n",
      "10847/10847 [==============================] - 10s 890us/step - loss: 25.7401 - accuracy: 2.7371e-04 - val_loss: 14.4623 - val_accuracy: 0.0000e+00\n",
      "Epoch 771/1000\n",
      "10847/10847 [==============================] - 10s 943us/step - loss: 25.7072 - accuracy: 2.9244e-04 - val_loss: 15.9639 - val_accuracy: 0.0000e+00\n",
      "Epoch 772/1000\n",
      "10847/10847 [==============================] - 10s 882us/step - loss: 25.6623 - accuracy: 2.9244e-04 - val_loss: 16.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 773/1000\n",
      "10847/10847 [==============================] - 10s 938us/step - loss: 25.6625 - accuracy: 2.8379e-04 - val_loss: 17.9613 - val_accuracy: 0.0000e+00\n",
      "Epoch 774/1000\n",
      "10847/10847 [==============================] - 10s 881us/step - loss: 25.6628 - accuracy: 2.8379e-04 - val_loss: 15.5945 - val_accuracy: 3.6911e-05\n",
      "Epoch 775/1000\n",
      "10847/10847 [==============================] - 10s 897us/step - loss: 25.6871 - accuracy: 2.7803e-04 - val_loss: 14.9843 - val_accuracy: 0.0000e+00\n",
      "Epoch 776/1000\n",
      "10847/10847 [==============================] - 10s 898us/step - loss: 25.7255 - accuracy: 2.8667e-04 - val_loss: 14.3866 - val_accuracy: 0.0000e+00\n",
      "Epoch 777/1000\n",
      "10847/10847 [==============================] - 10s 923us/step - loss: 25.6757 - accuracy: 2.9820e-04 - val_loss: 17.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 778/1000\n",
      "10847/10847 [==============================] - 11s 973us/step - loss: 25.6852 - accuracy: 2.9388e-04 - val_loss: 14.0767 - val_accuracy: 0.0000e+00\n",
      "Epoch 779/1000\n",
      "10847/10847 [==============================] - 15s 1ms/step - loss: 25.6388 - accuracy: 2.8379e-04 - val_loss: 14.1616 - val_accuracy: 0.0000e+00\n",
      "Epoch 780/1000\n",
      "10847/10847 [==============================] - 12s 1ms/step - loss: 25.6354 - accuracy: 2.9964e-04 - val_loss: 15.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 781/1000\n",
      "10847/10847 [==============================] - 11s 1ms/step - loss: 25.6590 - accuracy: 2.9676e-04 - val_loss: 16.1039 - val_accuracy: 3.6911e-05\n",
      "Epoch 782/1000\n",
      "10847/10847 [==============================] - 10s 959us/step - loss: 25.6936 - accuracy: 2.9100e-04 - val_loss: 16.9023 - val_accuracy: 0.0000e+00\n",
      "Epoch 783/1000\n",
      "10847/10847 [==============================] - 10s 882us/step - loss: 25.7054 - accuracy: 2.7515e-04 - val_loss: 15.6625 - val_accuracy: 0.0000e+00\n",
      "Epoch 784/1000\n",
      "10847/10847 [==============================] - 10s 910us/step - loss: 25.6377 - accuracy: 2.8091e-04 - val_loss: 13.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 785/1000\n",
      "10847/10847 [==============================] - 10s 950us/step - loss: 25.7229 - accuracy: 2.8956e-04 - val_loss: 14.7442 - val_accuracy: 7.3823e-05\n",
      "Epoch 786/1000\n",
      "10847/10847 [==============================] - 10s 919us/step - loss: 25.6997 - accuracy: 2.9532e-04 - val_loss: 16.2581 - val_accuracy: 8.4896e-04\n",
      "Epoch 787/1000\n",
      "10847/10847 [==============================] - 10s 931us/step - loss: 25.6654 - accuracy: 2.6362e-04 - val_loss: 13.6122 - val_accuracy: 0.0000e+00\n",
      "Epoch 788/1000\n",
      "10847/10847 [==============================] - 10s 918us/step - loss: 25.6864 - accuracy: 2.7659e-04 - val_loss: 14.8464 - val_accuracy: 0.0000e+00\n",
      "Epoch 789/1000\n",
      "10847/10847 [==============================] - 10s 929us/step - loss: 25.6883 - accuracy: 2.8956e-04 - val_loss: 14.7841 - val_accuracy: 0.0000e+00\n",
      "Epoch 790/1000\n",
      "10847/10847 [==============================] - 10s 904us/step - loss: 25.7209 - accuracy: 2.6939e-04 - val_loss: 18.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 791/1000\n",
      "10847/10847 [==============================] - 10s 894us/step - loss: 25.7526 - accuracy: 2.8667e-04 - val_loss: 15.6140 - val_accuracy: 0.0000e+00\n",
      "Epoch 792/1000\n",
      "10847/10847 [==============================] - 10s 893us/step - loss: 25.7171 - accuracy: 2.7659e-04 - val_loss: 14.1579 - val_accuracy: 0.0000e+00\n",
      "Epoch 793/1000\n",
      "10847/10847 [==============================] - 10s 910us/step - loss: 25.7047 - accuracy: 2.7371e-04 - val_loss: 15.2658 - val_accuracy: 0.0000e+00\n",
      "Epoch 794/1000\n",
      "10847/10847 [==============================] - 10s 907us/step - loss: 25.7205 - accuracy: 2.7515e-04 - val_loss: 14.1067 - val_accuracy: 0.0000e+00\n",
      "Epoch 795/1000\n",
      "10847/10847 [==============================] - 10s 910us/step - loss: 25.7391 - accuracy: 3.0108e-04 - val_loss: 14.2843 - val_accuracy: 0.0000e+00\n",
      "Epoch 796/1000\n",
      "10847/10847 [==============================] - 10s 878us/step - loss: 25.7184 - accuracy: 2.6218e-04 - val_loss: 18.2877 - val_accuracy: 0.0000e+00\n",
      "Epoch 797/1000\n",
      "10847/10847 [==============================] - 10s 898us/step - loss: 25.7108 - accuracy: 2.7515e-04 - val_loss: 15.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 798/1000\n",
      "10847/10847 [==============================] - 9s 867us/step - loss: 25.6883 - accuracy: 2.9676e-04 - val_loss: 13.7455 - val_accuracy: 0.0000e+00\n",
      "Epoch 799/1000\n",
      " 1042/10847 [=>............................] - ETA: 9s - loss: 25.6060 - accuracy: 2.6991e-04"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "print(mse(train_pred, y_train))\n",
    "print(mape(train_pred, y_train))\n",
    "test_pred = model.predict(X_test)\n",
    "print(mse(test_pred, y_test))\n",
    "print(mape(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(test_pred.flatten(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = model_path+'model_nonzero_32to38_3layer5unit_1000_erode.sav'\n",
    "pickle.dump(model, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063/1063 [==============================] - 1s 842us/step - loss: 56.8737 - accuracy: 8.8204e-04\n",
      "[56.87367630004883, 0.0008820416405797005]\n"
     ]
    }
   ],
   "source": [
    "load_model = pickle.load(open(file, 'rb'))\n",
    "result = load_model.evaluate(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_df = pd.DataFrame(history.history)\n",
    "model_df[['loss', 'val_loss']].plot()\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Training Period\", pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[['accuracy', 'val_accuracy']].plot()\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuray Over Training Period\", pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory vs Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = y_test.flatten()\n",
    "y = test_pred.flatten()\n",
    "m, b, r, p, st_er = stats.linregress(x,y) \n",
    "\n",
    "yfit = [b + m * xi for xi in x]\n",
    "yisx = [0 + 1 * xi for xi in x]\n",
    "plt.plot(x, yfit)\n",
    "plt.plot(x, yisx)\n",
    "\n",
    "plt.scatter(y_test, test_pred,  color='black')\n",
    "plt.axis([0,100, 0, 100])\n",
    "plt.xlabel(\"Theory (nT)\")\n",
    "plt.ylabel(\"Prediction (nT)\")\n",
    "plt.title(\"Neural Network Prediction vs Theory\", fontsize=15)\n",
    "# print(r, st_er)\n",
    "print(\"r: {:.5f}, st_er: {:.6f}\".format(r, st_er))\n",
    "print(\"y = \"+str(round(m,4))+\"*x + \"+str(round(b,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847/847 [==============================] - 1s 744us/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(X4_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/z02d0fq542v7qg_9kr87__k40000gp/T/ipykernel_30186/2364276288.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df4_pred['predict'] = test_pred\n"
     ]
    }
   ],
   "source": [
    "df4_pred['predict'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>mini_exp</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>theory</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>936040</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>-281.228516</td>\n",
       "      <td>-281.580200</td>\n",
       "      <td>-298.687897</td>\n",
       "      <td>-313.737274</td>\n",
       "      <td>-312.011200</td>\n",
       "      <td>6.323732</td>\n",
       "      <td>7.221442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936041</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>-470.337860</td>\n",
       "      <td>-472.075500</td>\n",
       "      <td>-488.780823</td>\n",
       "      <td>-502.790314</td>\n",
       "      <td>-501.399567</td>\n",
       "      <td>5.692159</td>\n",
       "      <td>5.189351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936042</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>-681.214478</td>\n",
       "      <td>-683.935608</td>\n",
       "      <td>-700.522400</td>\n",
       "      <td>-713.198364</td>\n",
       "      <td>-711.765076</td>\n",
       "      <td>5.156662</td>\n",
       "      <td>3.756080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936043</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>-892.559753</td>\n",
       "      <td>-896.184509</td>\n",
       "      <td>-911.637207</td>\n",
       "      <td>-924.472595</td>\n",
       "      <td>-923.017944</td>\n",
       "      <td>4.694756</td>\n",
       "      <td>4.013589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936079</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>-1471.209351</td>\n",
       "      <td>-1475.378540</td>\n",
       "      <td>-1489.757202</td>\n",
       "      <td>-1499.828979</td>\n",
       "      <td>-1503.126099</td>\n",
       "      <td>3.883065</td>\n",
       "      <td>3.901836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046804</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>-610.252991</td>\n",
       "      <td>-613.019775</td>\n",
       "      <td>-628.576294</td>\n",
       "      <td>-640.380493</td>\n",
       "      <td>-640.784180</td>\n",
       "      <td>6.022675</td>\n",
       "      <td>3.667385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046805</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>-460.002319</td>\n",
       "      <td>-461.472900</td>\n",
       "      <td>-478.441254</td>\n",
       "      <td>-491.319244</td>\n",
       "      <td>-490.660767</td>\n",
       "      <td>6.719324</td>\n",
       "      <td>5.300120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046806</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>-321.722260</td>\n",
       "      <td>-321.674591</td>\n",
       "      <td>-340.263275</td>\n",
       "      <td>-354.678894</td>\n",
       "      <td>-352.521301</td>\n",
       "      <td>7.573551</td>\n",
       "      <td>7.087917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046807</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>-196.516602</td>\n",
       "      <td>-195.509140</td>\n",
       "      <td>-214.553329</td>\n",
       "      <td>-230.615768</td>\n",
       "      <td>-227.110611</td>\n",
       "      <td>8.658540</td>\n",
       "      <td>8.441931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046808</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>-89.895828</td>\n",
       "      <td>-89.635216</td>\n",
       "      <td>-108.126854</td>\n",
       "      <td>-123.815941</td>\n",
       "      <td>-120.935234</td>\n",
       "      <td>10.102723</td>\n",
       "      <td>8.446331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27093 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         exp  mini_exp   i   j   k        mean0        mean1        mean2  \\\n",
       "936040    36         6   8  33  40  -281.228516  -281.580200  -298.687897   \n",
       "936041    36         6   8  33  41  -470.337860  -472.075500  -488.780823   \n",
       "936042    36         6   8  33  42  -681.214478  -683.935608  -700.522400   \n",
       "936043    36         6   8  33  43  -892.559753  -896.184509  -911.637207   \n",
       "936079    36         6   8  34  15 -1471.209351 -1475.378540 -1489.757202   \n",
       "...      ...       ...  ..  ..  ..          ...          ...          ...   \n",
       "1046804   36         6  35  36  20  -610.252991  -613.019775  -628.576294   \n",
       "1046805   36         6  35  36  21  -460.002319  -461.472900  -478.441254   \n",
       "1046806   36         6  35  36  22  -321.722260  -321.674591  -340.263275   \n",
       "1046807   36         6  35  36  23  -196.516602  -195.509140  -214.553329   \n",
       "1046808   36         6  35  36  24   -89.895828   -89.635216  -108.126854   \n",
       "\n",
       "               mean3        mean4     theory   predict  \n",
       "936040   -313.737274  -312.011200   6.323732  7.221442  \n",
       "936041   -502.790314  -501.399567   5.692159  5.189351  \n",
       "936042   -713.198364  -711.765076   5.156662  3.756080  \n",
       "936043   -924.472595  -923.017944   4.694756  4.013589  \n",
       "936079  -1499.828979 -1503.126099   3.883065  3.901836  \n",
       "...              ...          ...        ...       ...  \n",
       "1046804  -640.380493  -640.784180   6.022675  3.667385  \n",
       "1046805  -491.319244  -490.660767   6.719324  5.300120  \n",
       "1046806  -354.678894  -352.521301   7.573551  7.087917  \n",
       "1046807  -230.615768  -227.110611   8.658540  8.441931  \n",
       "1046808  -123.815941  -120.935234  10.102723  8.446331  \n",
       "\n",
       "[27093 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>mini_exp</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>mean0</th>\n",
       "      <th>mean1</th>\n",
       "      <th>mean2</th>\n",
       "      <th>mean3</th>\n",
       "      <th>mean4</th>\n",
       "      <th>theory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>901120</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901121</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901122</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901123</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901124</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081339</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081340</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081341</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081342</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081343</th>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180224 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         exp  mini_exp   i   j   k  mean0  mean1  mean2  mean3  mean4  theory\n",
       "901120    36         6   0   0   0    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "901121    36         6   0   0   1    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "901122    36         6   0   0   2    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "901123    36         6   0   0   3    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "901124    36         6   0   0   4    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "...      ...       ...  ..  ..  ..    ...    ...    ...    ...    ...     ...\n",
       "1081339   36         6  43  63  59    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "1081340   36         6  43  63  60    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "1081341   36         6  43  63  61    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "1081342   36         6  43  63  62    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "1081343   36         6  43  63  63    0.0    0.0    0.0    0.0    0.0     0.0\n",
       "\n",
       "[180224 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/z02d0fq542v7qg_9kr87__k40000gp/T/ipykernel_30186/3257651465.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predict'] = 0.00\n"
     ]
    }
   ],
   "source": [
    "df_test['predict'] = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_test[['i', 'j', 'k', 'predict']]\n",
    "df_pre = df4_pred[['i', 'j', 'k', 'predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 180224 entries, 901120 to 1081343\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   i        180224 non-null  int64  \n",
      " 1   j        180224 non-null  int64  \n",
      " 2   k        180224 non-null  int64  \n",
      " 3   predict  180224 non-null  float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_out.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df_pre)):\n",
    "    i = df_pre.iloc[x, :]['i'].astype(int)\n",
    "    j = df_pre.iloc[x, :]['j'].astype(int)\n",
    "    k = df_pre.iloc[x, :]['k'].astype(int)\n",
    "    pred = df_pre.iloc[x, :]['predict']\n",
    "    idx = df_out[(df_out['i']==i) & (df_out['j']==j) & (df_out['k']==k)].index\n",
    "    df_out.loc[idx, 'predict']= pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>936040</th>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>7.221442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936041</th>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>5.189351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936042</th>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>3.756080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936043</th>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>4.013589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936079</th>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>3.901836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046804</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>3.667385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046805</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>5.300120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046806</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>7.087917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046807</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>8.441931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046808</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>8.446331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27093 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          i   j   k   predict\n",
       "936040    8  33  40  7.221442\n",
       "936041    8  33  41  5.189351\n",
       "936042    8  33  42  3.756080\n",
       "936043    8  33  43  4.013589\n",
       "936079    8  34  15  3.901836\n",
       "...      ..  ..  ..       ...\n",
       "1046804  35  36  20  3.667385\n",
       "1046805  35  36  21  5.300120\n",
       "1046806  35  36  22  7.087917\n",
       "1046807  35  36  23  8.441931\n",
       "1046808  35  36  24  8.446331\n",
       "\n",
       "[27093 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>931880</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        i   j   k  predict\n",
       "931880  7  32  40      0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[(df_out['i']==7) & (df_out['j']==32) & (df_out['k']==40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>901120</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901123</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081339</th>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081340</th>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081341</th>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081342</th>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081343</th>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180224 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          i   j   k  predict\n",
       "901120    0   0   0      0.0\n",
       "901121    0   0   1      0.0\n",
       "901122    0   0   2      0.0\n",
       "901123    0   0   3      0.0\n",
       "901124    0   0   4      0.0\n",
       "...      ..  ..  ..      ...\n",
       "1081339  43  63  59      0.0\n",
       "1081340  43  63  60      0.0\n",
       "1081341  43  63  61      0.0\n",
       "1081342  43  63  62      0.0\n",
       "1081343  43  63  63      0.0\n",
       "\n",
       "[180224 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(img_path+\"nn_nonzero_32to38_erode.txt\", df_out[['i', 'j', 'k', 'predict']], fmt=\"%i %i %i %s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
